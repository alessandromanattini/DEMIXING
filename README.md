#  Progressive Inference for Music Demixing

Using denoising diffusion approaches to train music demixing (MDX) models is promising but requires retraining large and carefully tuned neural networks (Plaja-Roglans,2022). Instead, we will explore a related yet different approach: can we improve separation quality solely by scheduling the inference process using a diffusion-inspired strategy even without retraining? By experimenting with existing MDX models (Spleeter by Deezer, Meta‚Äôs Demucs, ByteDance‚Äôs BS-Roformer, etc.), this project focuses on an exciting opportunity to explore and possibly enhance the performance of state-of-the-art AI techniques.

## Group:

- ####  Giorgio Magalini &nbsp;([@Giorgio-Magalini](https://github.com/Giorgio-Magalini))<br> 10990259 &nbsp;&nbsp; giorgio.magalini@mail.polimi.it

- ####  Alessandro Manattini &nbsp;([@alessandromanattini](https://github.com/alessandromanattini))<br> 11006826 &nbsp;&nbsp; alessandro.manattini@mail.polimi.it

- ####  Filippo Marri &nbsp;([@filippomarri](https://github.com/filippomarri))<br> 10110508 &nbsp;&nbsp; filippo.marri@mail.polimi.it

## Checklist

### Macrotasks
1.	Preparare (un tot di secondi per ogni traccia) e caricare il database ‚úÖ
2.	Mixaggio a 0,25 per tutte le stems ed eventuale confronto con mixture ‚úÖ
3.	Analisi del predittore Oracle e prove of concept: dimostrare che alzando il volume (coefficiente) di una stem rispetto alle altre, si ottiene un risultato migliore in fase di estrazione della stem stessa. ‚úÖ *DA RIVEDERE*
4.	Capire come modificare la schedule nel modello üîÑ
5.	Scegliere la schedule che ci piace di pi√π e dare una motivazione fra queste [schedulesssss](https://arxiv.org/pdf/2206.00364).
6.	Si fanno i test con diverse schedule confrontandoli con DEMUCS chiamato una volta sola
7.	Si scrive il report

--------------------most valuable product--------------------

8.	In base a quanto tempo abbiamo e a che punto siamo si possono aggiungere, volendo, altre schedules, altre stems o, addirittura, condurre la stessa analisi su un altro modello.

### Microtasks Completate
- Implementazione ‚Å†SDR, SIR, SAR
- Riscrittura del codice come Jupyter Notebook
- ‚Å†Taratura della soglia che definisce l‚Äôenergia necessaria affinch√© un chunk sia considerato non silenzioso
- ‚Å†Valutazione dell‚Äôoverlap: inserirlo o evitarlo?
- ‚Å†Rendere iterativa la procedura di aggiornamento dei gain da mandare in ingresso alla rete di demixing
- Tentativo di sostituzione di bss_eval_sources con eval_mus. Lasciata bss_eval_sources nonostante l'elevato onere computazionale perch√© l'altra d√† problemi di compatibilit√†
- prendere tutte le canzoni del dataset, applicare la funzione trim di librosa e salvare le tracce processate in una cartella locale in modo tale da prendere sempre i soliti primi trenta secondi sicuri che non ci sia silenzio n√© prima n√© dopo. Consiglia quindi di salvare tutto in una cartella creandoci un dataset personale.
- sostituire un mix create con gain omogeneo dagli stems alla mixture da usare come reference track.
- Controllare che i file audio abbiano tutti la stessa bitdepth. (NON IMPLEMENTATO MA CONTROLLATO DAL FINDER)
- Vanno normalizzate le stems per la new_mixture? No perch√© la variazione di SDR in funzione della differenza di volume dei segnali √® trascurabile nella modalit√† attuale di valutazione.
- Sostituire la funzione di mir_eval con quella che si trova a questi [link](https://lightning.ai/docs/torchmetrics/stable/audio/scale_invariant_signal_distortion_ratio.html)
- Controllare sui datasheet di DEMUCS la normalizzazione usata per l‚Äôallenamento del modello e utilizzare la stessa nel codice. Durante la costruzione dei metadati nel metodo build_metadata, se normalize √® impostato su True, viene calcolato il valore RMS dell'intera traccia per ciascuna sorgente. Questi valori RMS vengono poi utilizzati per normalizzare i segmenti audio durante il training. La normalizzazione in DEMUCS viene quindi effettuata a livello di dataset, utilizzando i valori RMS precomputati delle tracce complete. <mark> Questo approccio garantisce che le variazioni di ampiezza tra le diverse tracce non influenzino negativamente il processo di apprendimento del modello. (con normalizzazione peggiora di 1‚Ä∞).
Per quanto riguarda il dataset creato si √® preferito normalizzare le tracce a 1 perch√© con l'RMS distorce. Senza normalizzazione il volume sarebbe troppo basso. </mark>
- Confronto fra gli SDR delle tracce estratte dichiarati da DEMUCS ed i nostri (con gain uniformi a 0.25) in fase di valutazione del corretto funzionamento del modello. 
    - SDR ‚âà 5-10 dB per separazioni pi√π semplici (ad esempio, separazione di voce da accompagnamento musicale).
    - SDR ‚âà 10-20 dB per separazioni pi√π accurate (come la separazione di basso, batteria, e voce da un mix complesso).
- Utilizzare gi√† una sorta di schedule e anzich√© fare un bar plot si raffigura un line plot con sdr dello stem target sull‚Äôasse delle y e numero di iterazioni sull‚Äôasse delle ascisse.
- Implementare diverse schedules

### Microtasks Da fare
- Per un‚Äôintuitiva rappresentazione dei risultati, ci consiglia di raffigurare l‚ÄôSDR dell‚Äôoracle predictor come limite superiore e quello del DEMUCS con una sola passata come limite inferiore. I nostri risultati saranno (o ci aspettiamo che siano) collocati all‚Äôinterno di questo intervallo.
- Controllare l'overlapping nella funzione separate_sources.

## Branches
- main: codice funzionante ma che gira su CPU
- test_Filippo: codice che prova a girare su MPS


