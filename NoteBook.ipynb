{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progressive Inference for Music Demixing\n",
    "## ID: L12\n",
    "Description: Using denoising diffusion approaches to train music demixing (MDX) models is\n",
    "promising but requires retraining large and carefully tuned neural networks (Plaja-Roglans,\n",
    "2022). Instead, we will explore a related yet different approach: can we improve separation\n",
    "quality solely by scheduling the inference process using a diffusion-inspired strategy even\n",
    "without retraining? By experimenting with existing MDX models (Spleeter by Deezer,Meta’s Demucs, ByteDance’s BS-Roformer, etc.), this project offers an exciting opportunity\n",
    "to explore and possibly enhance the performance of state-of-the-art AI techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "(Plaja-Roglans, 2022) https://ismir2022program.ismir.net/poster_262.html\n",
    "Denoising Diffusion Probabilistic Models: https://arxiv.org/abs/2006.11239\n",
    "MDX Challenge 2021: https://arxiv.org/abs/2108.13559\n",
    "MDX Challenge 2023: https://arxiv.org/abs/2308.06979\n",
    "Overview of state-of-the-art MDX models:\n",
    "https://paperswithcode.com/sota/music-source-separation-on-musdb18-hq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary step: Install and Import Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 1)) (3.9.4)\n",
      "Requirement already satisfied: numpy in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
      "Requirement already satisfied: IPython in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 3)) (8.18.1)\n",
      "Requirement already satisfied: torch in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 4)) (2.6.0)\n",
      "Requirement already satisfied: torchaudio in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 5)) (2.6.0)\n",
      "Requirement already satisfied: mir_eval in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from -r requirements.txt (line 6)) (0.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r requirements.txt (line 1)) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r requirements.txt (line 1)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r requirements.txt (line 1)) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from matplotlib->-r requirements.txt (line 1)) (6.5.2)\n",
      "Requirement already satisfied: decorator in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from IPython->-r requirements.txt (line 3)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from IPython->-r requirements.txt (line 3)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from IPython->-r requirements.txt (line 3)) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from IPython->-r requirements.txt (line 3)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from IPython->-r requirements.txt (line 3)) (2.19.1)\n",
      "Requirement already satisfied: stack-data in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from IPython->-r requirements.txt (line 3)) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from IPython->-r requirements.txt (line 3)) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from IPython->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from IPython->-r requirements.txt (line 3)) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from IPython->-r requirements.txt (line 3)) (4.9.0)\n",
      "Requirement already satisfied: filelock in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from torch->-r requirements.txt (line 4)) (3.18.0)\n",
      "Requirement already satisfied: networkx in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from torch->-r requirements.txt (line 4)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from torch->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from torch->-r requirements.txt (line 4)) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from torch->-r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.4.0 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from mir_eval->-r requirements.txt (line 6)) (1.13.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib->-r requirements.txt (line 1)) (3.21.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from jedi>=0.16->IPython->-r requirements.txt (line 3)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from pexpect>4.3->IPython->-r requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython->-r requirements.txt (line 3)) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from jinja2->torch->-r requirements.txt (line 4)) (3.0.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from stack-data->IPython->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from stack-data->IPython->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from stack-data->IPython->-r requirements.txt (line 3)) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchviz\n",
      "  Using cached torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: torch in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from torchviz) (2.6.0)\n",
      "Requirement already satisfied: graphviz in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from torchviz) (0.20.3)\n",
      "Requirement already satisfied: filelock in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from torch->torchviz) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from torch->torchviz) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from torch->torchviz) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from torch->torchviz) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from torch->torchviz) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from torch->torchviz) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/giorgiomagalini/Library/Python/3.9/lib/python/site-packages (from jinja2->torch->torchviz) (3.0.2)\n",
      "Using cached torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
      "Installing collected packages: torchviz\n",
      "Successfully installed torchviz-0.0.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from mir_eval import separation\n",
    "from torchaudio.pipelines import HDEMUCS_HIGH_MUSDB_PLUS\n",
    "from torchaudio.transforms import Fade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HDemucs(\n",
       "  (freq_encoder): ModuleList(\n",
       "    (0): _HEncLayer(\n",
       "      (conv): Conv2d(4, 48, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): _HEncLayer(\n",
       "      (conv): Conv2d(48, 96, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): _HEncLayer(\n",
       "      (conv): Conv2d(96, 192, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): _HEncLayer(\n",
       "      (conv): Conv2d(192, 384, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): _HEncLayer(\n",
       "      (conv): Conv2d(384, 768, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): _HEncLayer(\n",
       "      (conv): Conv1d(768, 1536, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv1d(1536, 3072, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (freq_decoder): ModuleList(\n",
       "    (0): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(1536, 768, kernel_size=(4,), stride=(2,))\n",
       "      (norm2): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv1d(1536, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (1): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(768, 384, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv2d(768, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (2): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(384, 192, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (3): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(192, 96, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (4): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(96, 48, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (5): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(48, 16, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "  )\n",
       "  (time_encoder): ModuleList(\n",
       "    (0): _HEncLayer(\n",
       "      (conv): Conv1d(2, 48, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(48, 96, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): _HEncLayer(\n",
       "      (conv): Conv1d(48, 96, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): _HEncLayer(\n",
       "      (conv): Conv1d(96, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): _HEncLayer(\n",
       "      (conv): Conv1d(192, 384, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): _HEncLayer(\n",
       "      (conv): Conv1d(384, 768, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Identity()\n",
       "      (norm2): Identity()\n",
       "      (dconv): Identity()\n",
       "    )\n",
       "  )\n",
       "  (time_decoder): ModuleList(\n",
       "    (0): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(768, 384, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
       "      (rewrite): Identity()\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (1): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(384, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (2): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(192, 96, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(192, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (3): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(96, 48, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(96, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (4): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(48, 8, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(48, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "  )\n",
       "  (freq_emb): _ScaledEmbedding(\n",
       "    (embedding): Embedding(512, 48)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundle = HDEMUCS_HIGH_MUSDB_PLUS\n",
    "model = bundle.get_model()\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset at: https://zenodo.org/records/3338373\n",
    "\n",
    "Set the path of the downloaded dataset in DATASET_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path set to: /Users/giorgiomagalini/Documents/_DocumentiUtente/Uni/PoliMi/CAPSTONE/Code\n"
     ]
    }
   ],
   "source": [
    "# Prompt the user for the absolute path of the dataset\n",
    "DATASET_PATH = input(\"Please enter the absolute path for the dataset: \")\n",
    "print(f\"Dataset path set to: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshlex\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Prompt the user for the absolute path of the dataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m DATASET_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPlease enter the absolute path for the dataset: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m quoted_path \u001b[38;5;241m=\u001b[39m shlex\u001b[38;5;241m.\u001b[39mquote(DATASET_PATH)  \u001b[38;5;66;03m# Safely quote the path\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset path set to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquoted_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import shlex\n",
    "# Prompt the user for the absolute path of the dataset\n",
    "DATASET_PATH = input(\"Please enter the absolute path for the dataset: \")\n",
    "quoted_path = shlex.quote(DATASET_PATH)  # Safely quote the path\n",
    "print(f\"Dataset path set to: {quoted_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Users/giorgiomagalini/Documents/_DocumentiUtente/Uni/PoliMi/CAPSTONE/Code/musdb18hq/test/AM Contra - Heart Peripheral/mixture.wav...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Couldn't find appropriate backend to handle uri '/Users/giorgiomagalini/Documents/_DocumentiUtente/Uni/PoliMi/CAPSTONE/Code/musdb18hq/test/AM Contra - Heart Peripheral/mixture.wav' and format None.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m file_path \u001b[38;5;241m=\u001b[39m shlex\u001b[38;5;241m.\u001b[39mquote(file_path)\n\u001b[0;32m---> 37\u001b[0m waveform, sr \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Keep only the first 30s\u001b[39;00m\n\u001b[1;32m     40\u001b[0m segment_samples \u001b[38;5;241m=\u001b[39m SEGMENT \u001b[38;5;241m*\u001b[39m sr\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchaudio/_backend/utils.py:204\u001b[0m, in \u001b[0;36mget_load_func.<locals>.load\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m    119\u001b[0m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    120\u001b[0m     frame_offset: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m     backend: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    127\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    By default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m            `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     backend \u001b[38;5;241m=\u001b[39m \u001b[43mdispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mload(uri, frame_offset, num_frames, normalize, channels_first, \u001b[38;5;28mformat\u001b[39m, buffer_size)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torchaudio/_backend/utils.py:116\u001b[0m, in \u001b[0;36mget_load_func.<locals>.dispatcher\u001b[0;34m(uri, format, backend_name)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcan_decode(uri, \u001b[38;5;28mformat\u001b[39m):\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m backend\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find appropriate backend to handle uri \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and format \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mformat\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Couldn't find appropriate backend to handle uri '/Users/giorgiomagalini/Documents/_DocumentiUtente/Uni/PoliMi/CAPSTONE/Code/musdb18hq/test/AM Contra - Heart Peripheral/mixture.wav' and format None."
     ]
    }
   ],
   "source": [
    "# Load dataset and choose the length of the tracks for each song (in seconds)\n",
    "DATASET_FOLDER = DATASET_PATH + \"/musdb18hq/test\"\n",
    "SEGMENT = 30  # We'll keep exactly 30 seconds from each track\n",
    "\n",
    "# !!! --> PAY ATTENTION TO THE SILENT PORTIONS OF THE TRACKS, THEY CAN CAUSE ERRORS IN THE SEPARATION PROCESS <-- !!!\n",
    "# You should choose a portion of the track that contains all the instrument without the channel sums being zero\n",
    "# NB: if you encounter a silent portion of the track, you will skip the evaluation for that stem!\n",
    "\n",
    "track_folders = sorted(\n",
    "    folder for folder in os.listdir(DATASET_FOLDER)\n",
    "    if os.path.isdir(os.path.join(DATASET_FOLDER, folder))\n",
    ")\n",
    "\n",
    "# Dictionary to store {track_folder -> {stem_name -> waveform}}\n",
    "dataset_dict = {}\n",
    "\n",
    "# Each subfolder in musdb18hq/test corresponds to a track\n",
    "for track_folder in track_folders:\n",
    "    track_path = os.path.join(DATASET_FOLDER, track_folder)\n",
    "    if not os.path.isdir(track_path):\n",
    "        continue\n",
    "\n",
    "    # Prepare a sub-dictionary for this track\n",
    "    stems_dict = {}\n",
    "    stem_names = [\"mixture\", \"drums\", \"bass\", \"vocals\", \"other\"]\n",
    "\n",
    "    for stem_name in stem_names:\n",
    "        file_path = os.path.join(track_path, f\"{stem_name}.wav\")\n",
    "        \n",
    "        if not os.path.isfile(file_path):\n",
    "            print(f\"Warning: file not found {file_path}\")\n",
    "            continue\n",
    "\n",
    "        # Load full audio\n",
    "        print(f\"Loading {file_path}...\")\n",
    "        file_path = shlex.quote(file_path)\n",
    "        waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "        # Keep only the first 30s\n",
    "        segment_samples = SEGMENT * sr\n",
    "        waveform_segment = waveform[:, :segment_samples]\n",
    "\n",
    "        stems_dict[stem_name] = waveform_segment\n",
    "\n",
    "    dataset_dict[track_folder] = stems_dict\n",
    "\n",
    "print(\"Loaded tracks:\", list(dataset_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Processing a Single Track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Choose a Track to Process\n",
    "Try analyze different tracks by changing the index of ***track_names[index]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you have a dictionary with track_folder as the key,\n",
    "# and a sub-dict with \"mixture\", \"drums\", \"bass\", \"vocals\", \"other\" waveforms\n",
    "track_names = list(dataset_dict.keys())\n",
    "\n",
    "\n",
    "track_chosen = track_names[25]\n",
    "print(\"Chosen track name:\", track_chosen)\n",
    "\n",
    "stems_available = list(dataset_dict[track_chosen].keys())\n",
    "print(\"Stems:\", stems_available)  # e.g. ['mixture', 'drums', 'bass', 'vocals', 'other']\n",
    "\n",
    "# Check duration\n",
    "mixture_waveform = dataset_dict[track_chosen][\"mixture\"]\n",
    "duration_seconds = mixture_waveform.shape[1] / sample_rate\n",
    "print(f\"Duration (seconds): {duration_seconds}\")\n",
    "\n",
    "# Ensure we have all 5 stems\n",
    "if len(stems_available) < 5:\n",
    "    print(\"Warning: Not all stems found. This track might be incomplete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Prepare the Data for Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_waveform = mixture_waveform.to(device)\n",
    "\n",
    "# Normalization across the channels\n",
    "ref = mixture_waveform.mean(0)  # (2, samples) -> (samples,)\n",
    "\n",
    "# Singal with zero mean and unit variance\n",
    "mixture_norm = (mixture_waveform - ref.mean()) / ref.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_sources(\n",
    "    model,\n",
    "    mix,\n",
    "    segment=30,\n",
    "    overlap=0.0,  # set to 0.0 to avoid chunk repetition\n",
    "    device=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply model to a given mixture. Use fade, and add segments together in order to add model segment by segment.\n",
    "\n",
    "    Args:\n",
    "        segment (int): segment length in seconds\n",
    "        device (torch.device, str, or None): if provided, device on which to\n",
    "            execute the computation, otherwise `mix.device` is assumed.\n",
    "            When `device` is different from `mix.device`, only local computations will\n",
    "            be on `device`, while the entire tracks will be stored on `mix.device`.\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = mix.device\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "\n",
    "    batch, channels, length = mix.shape\n",
    "\n",
    "    # chunk_len for entire 30s, no overlap\n",
    "    chunk_len = int(sample_rate * segment * (1 + overlap))  # effectively 30s if overlap=0\n",
    "    start = 0\n",
    "    end = chunk_len\n",
    "\n",
    "    overlap_frames = int(overlap * sample_rate)\n",
    "    fade = Fade(fade_in_len=0, fade_out_len=overlap_frames, fade_shape=\"linear\")\n",
    "\n",
    "    # Prepare final buffer\n",
    "    final = torch.zeros(batch, len(model.sources), channels, length, device=device)\n",
    "\n",
    "    while start < length - overlap_frames:\n",
    "        chunk = mix[:, :, start:end]\n",
    "        with torch.no_grad():\n",
    "            out = model(chunk)\n",
    "        out = fade(out)\n",
    "        final[:, :, :, start:end] += out\n",
    "\n",
    "        if start == 0:\n",
    "            fade.fade_in_len = overlap_frames\n",
    "            start += chunk_len - overlap_frames\n",
    "        else:\n",
    "            start += chunk_len\n",
    "        end += chunk_len\n",
    "        if end >= length:\n",
    "            fade.fade_out_len = 0\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Run Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Separating 30-second track with no overlap...\")\n",
    "sources_tensor = separate_sources(\n",
    "    model,\n",
    "    mixture_norm[None],  # shape (1, channels, samples)\n",
    "    segment=30,\n",
    "    overlap=0.0,\n",
    "    device=device\n",
    ")[0]  # shape (4, channels, samples)\n",
    "\n",
    "# Undo normalization\n",
    "sources_tensor = sources_tensor * ref.std() + ref.mean()\n",
    "\n",
    "# Build a dict {stem_name -> predicted_stem}\n",
    "stem_names = model.sources  # ['drums', 'bass', 'other', 'vocals'] typically\n",
    "predicted_stems = dict(zip(stem_names, list(sources_tensor)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_results(original_source: torch.Tensor, predicted_source: torch.Tensor, source: str):\n",
    "    # Move to CPU\n",
    "    original_np = original_source.detach().cpu().numpy()\n",
    "    predicted_np = predicted_source.detach().cpu().numpy()\n",
    "\n",
    "    # If shape is (C, T), that's fine for mir_eval if C=2\n",
    "    # but let's ensure it's (2, T) not (T, 2)\n",
    "    # Usually PyTorch waveforms are (channels, samples),\n",
    "    # which is correct for bss_eval_sources.\n",
    "\n",
    "    # Verify the energy of the reference(sum of the absolutes for each channel).\n",
    "    energy = original_source.abs().sum(dim=1)\n",
    "    print(f\"{source} - Energy per channel: {energy}\")\n",
    "    \n",
    "    # If one of the cheannel has an energy below the energy threshold (1e-3), skip the evaluation\n",
    "    if (energy < 1e-3).any():\n",
    "        print(f\"Warning: {source} reference appears silent or nearly silent. Skipping evaluation for this stem.\")\n",
    "        return None  # oppure ritorna un valore di default o una stringa informativa\n",
    "    sdr, sir, sar, _ = separation.bss_eval_sources(\n",
    "        reference_sources=original_np,\n",
    "        estimated_sources=predicted_np\n",
    "    )\n",
    "\n",
    "    print(f\"--- {source} ---\")\n",
    "    print(\"SDR:\", sdr.mean())\n",
    "    print(\"SIR:\", sir.mean())\n",
    "    print(\"SAR:\", sar.mean())\n",
    "    print(\"----------------\")\n",
    "\n",
    "    return Audio(predicted_source, rate=sample_rate)\n",
    "\n",
    "# Retrieve references from dataset_dict\n",
    "drums_ref = dataset_dict[track_chosen][\"drums\"].to(device)\n",
    "bass_ref = dataset_dict[track_chosen][\"bass\"].to(device)\n",
    "vocals_ref = dataset_dict[track_chosen][\"vocals\"].to(device)\n",
    "other_ref = dataset_dict[track_chosen][\"other\"].to(device)\n",
    "\n",
    "# Predicted\n",
    "drums_pred = predicted_stems[\"drums\"]\n",
    "bass_pred  = predicted_stems[\"bass\"]\n",
    "vocals_pred = predicted_stems[\"vocals\"]\n",
    "other_pred = predicted_stems[\"other\"]\n",
    "\n",
    "# Evaluate each stem\n",
    "output_results(drums_ref, drums_pred, \"Drums\")\n",
    "output_results(bass_ref, bass_pred, \"Bass\")\n",
    "output_results(vocals_ref, vocals_pred, \"Vocals\")\n",
    "output_results(other_ref, other_pred, \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Collect evaluation metrics\n",
    "metrics = {\n",
    "    \"Drums\": output_results(drums_ref, drums_pred, \"Drums\"),\n",
    "    \"Bass\": output_results(bass_ref, bass_pred, \"Bass\"),\n",
    "    \"Vocals\": output_results(vocals_ref, vocals_pred, \"Vocals\"),\n",
    "    \"Other\": output_results(other_ref, other_pred, \"Other\"),\n",
    "}\n",
    "\n",
    "# Prepare data for plotting\n",
    "stems = list(metrics.keys())\n",
    "sdr_values = [separation.bss_eval_sources(drums_ref.cpu().numpy(), drums_pred.cpu().numpy())[0].mean(),\n",
    "              separation.bss_eval_sources(bass_ref.cpu().numpy(), bass_pred.cpu().numpy())[0].mean(),\n",
    "              separation.bss_eval_sources(vocals_ref.cpu().numpy(), vocals_pred.cpu().numpy())[0].mean(),\n",
    "              separation.bss_eval_sources(other_ref.cpu().numpy(), other_pred.cpu().numpy())[0].mean()]\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(stems, sdr_values, color='skyblue')\n",
    "plt.xlabel('Stems')\n",
    "plt.ylabel('SDR (Signal-to-Distortion Ratio)')\n",
    "plt.title('Evaluation Results: SDR for Each Stem')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
