{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progressive Inference for Music Demixing ID: L12\n",
    "Description: Using denoising diffusion approaches to train music demixing (MDX) models is\n",
    "promising but requires retraining large and carefully tuned neural networks (Plaja-Roglans,\n",
    "2022). Instead, we will explore a related yet different approach: can we improve separation\n",
    "quality solely by scheduling the inference process using a diffusion-inspired strategy even\n",
    "without retraining? By experimenting with existing MDX models (Spleeter by Deezer,Meta’s Demucs, ByteDance’s BS-Roformer, etc.), this project offers an exciting opportunity\n",
    "to explore and possibly enhance the performance of state-of-the-art AI techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "\n",
    "\n",
    "(Plaja-Roglans, 2022) https://ismir2022program.ismir.net/poster_262.html\n",
    "Denoising Diffusion Probabilistic Models: https://arxiv.org/abs/2006.11239\n",
    "MDX Challenge 2021: https://arxiv.org/abs/2108.13559\n",
    "MDX Challenge 2023: https://arxiv.org/abs/2308.06979\n",
    "Overview of state-of-the-art MDX models:\n",
    "https://paperswithcode.com/sota/music-source-separation-on-musdb18-hq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary step: Install and Import Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: IPython in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (9.1.0)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (2.6.0)\n",
      "Requirement already satisfied: torchaudio in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (2.6.0)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (2.2.4)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from -r requirements.txt (line 6)) (3.10.1)\n",
      "Requirement already satisfied: librosa in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from -r requirements.txt (line 7)) (0.11.0)\n",
      "Requirement already satisfied: torchmetrics in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from -r requirements.txt (line 8)) (1.7.1)\n",
      "Requirement already satisfied: decorator in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (5.14.3)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (4.13.1)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (0.61.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (1.4.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: standard-aifc in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (3.13.0)\n",
      "Requirement already satisfied: standard-sunau in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (3.13.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from torchmetrics->-r requirements.txt (line 8)) (0.14.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from jedi>=0.16->IPython->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 7)) (0.44.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from pexpect>4.3->IPython->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 7)) (4.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 7)) (2.32.3)\n",
      "Requirement already satisfied: wcwidth in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->-r requirements.txt (line 1)) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from scikit-learn>=1.1.0->librosa->-r requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 7)) (1.17.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from stack_data->IPython->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from stack_data->IPython->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from stack_data->IPython->-r requirements.txt (line 1)) (0.2.3)\n",
      "Requirement already satisfied: standard-chunk in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from standard-aifc->librosa->-r requirements.txt (line 7)) (3.13.0)\n",
      "Requirement already satisfied: audioop-lts in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from standard-aifc->librosa->-r requirements.txt (line 7)) (0.2.1)\n",
      "Requirement already satisfied: pycparser in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 7)) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from torchmetrics.audio import ScaleInvariantSignalDistortionRatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the Model and Device Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HDemucs(\n",
       "  (freq_encoder): ModuleList(\n",
       "    (0): _HEncLayer(\n",
       "      (conv): Conv2d(4, 48, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): _HEncLayer(\n",
       "      (conv): Conv2d(48, 96, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): _HEncLayer(\n",
       "      (conv): Conv2d(96, 192, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): _HEncLayer(\n",
       "      (conv): Conv2d(192, 384, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): _HEncLayer(\n",
       "      (conv): Conv2d(384, 768, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): _HEncLayer(\n",
       "      (conv): Conv1d(768, 1536, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv1d(1536, 3072, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (freq_decoder): ModuleList(\n",
       "    (0): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(1536, 768, kernel_size=(4,), stride=(2,))\n",
       "      (norm2): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv1d(1536, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (1): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(768, 384, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv2d(768, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (2): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(384, 192, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (3): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(192, 96, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (4): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(96, 48, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (5): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(48, 16, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "  )\n",
       "  (time_encoder): ModuleList(\n",
       "    (0): _HEncLayer(\n",
       "      (conv): Conv1d(2, 48, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(48, 96, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): _HEncLayer(\n",
       "      (conv): Conv1d(48, 96, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): _HEncLayer(\n",
       "      (conv): Conv1d(96, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): _HEncLayer(\n",
       "      (conv): Conv1d(192, 384, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): _HEncLayer(\n",
       "      (conv): Conv1d(384, 768, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Identity()\n",
       "      (norm2): Identity()\n",
       "      (dconv): Identity()\n",
       "    )\n",
       "  )\n",
       "  (time_decoder): ModuleList(\n",
       "    (0): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(768, 384, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
       "      (rewrite): Identity()\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (1): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(384, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (2): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(192, 96, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(192, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (3): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(96, 48, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(96, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (4): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(48, 8, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(48, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "  )\n",
       "  (freq_emb): _ScaledEmbedding(\n",
       "    (embedding): Embedding(512, 48)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundle = torchaudio.pipelines.HDEMUCS_HIGH_MUSDB_PLUS\n",
    "model = bundle.get_model()\n",
    "sample_rate = bundle.sample_rate\n",
    "\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # windows\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\") # macOS\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the Dataset and Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset at: https://zenodo.org/records/3338373"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_LENGTH = 30  # 30 seconds of audio from each song\n",
    "DATASET_FOLDER =  \"./musdb18hq/test\" # dataset should be inside the project folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary creation\n",
    "\n",
    "(Dataset Structure: `{track_folder -> {stem_name -> waveform}`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_non_silence_start(song):\n",
    "    \"\"\"\n",
    "    Given a song (dictionary of stem names -> waveform),\n",
    "    use librosa.effects.trim to find the starting index of non-silent \n",
    "    segments for each stem and return the highest start index.\n",
    "    \"\"\"\n",
    "    max_start = 0\n",
    "    for stem, waveform in song.items():\n",
    "        # Convert tensor waveform to numpy if necessary\n",
    "        if hasattr(waveform, \"detach\"):\n",
    "            waveform_np = waveform.detach().cpu().numpy()\n",
    "        else:\n",
    "            waveform_np = waveform\n",
    "        \n",
    "        # If waveform is multi-channel (shape: channels x samples)\n",
    "        if waveform_np.ndim > 1:\n",
    "            # Convert to mono using librosa.to_mono\n",
    "            waveform_np = librosa.to_mono(waveform_np)\n",
    "        else:\n",
    "            waveform_np = waveform_np.squeeze()\n",
    "\n",
    "        # Trim leading and trailing silence\n",
    "        # trim returns a tuple (trimmed_audio, (start, end))\n",
    "        trimmed, indices = librosa.effects.trim(waveform_np)\n",
    "        if indices.size and indices[0] > max_start:\n",
    "            max_start = indices[0]\n",
    "            \n",
    "    return max_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stem_silent(waveform, threshold=1e-4):\n",
    "    \"\"\"\n",
    "    Determines if a given song stem is not silent.\n",
    "    \n",
    "    Args:\n",
    "        waveform (torch.Tensor or np.ndarray): The audio waveform of the stem.\n",
    "        threshold (float): The amplitude threshold below which the stem is considered silent.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the stem is not silent, False otherwise.\n",
    "    \"\"\"\n",
    "    # Convert tensor waveform to numpy if necessary\n",
    "    if hasattr(waveform, \"detach\"):\n",
    "        waveform = waveform.detach().cpu().numpy()\n",
    "    \n",
    "    # If waveform is multi-channel (shape: channels x samples), convert to mono\n",
    "    if waveform.ndim > 1:\n",
    "        waveform = librosa.to_mono(waveform)\n",
    "    \n",
    "    # Check if the maximum absolute amplitude exceeds the threshold\n",
    "    return np.max(np.abs(waveform)) < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_dataset():\n",
    "    \"\"\"\n",
    "    Load the dataset from the specified folder.\n",
    "    Each subfolder in the dataset corresponds to a song.\n",
    "    Each song contains multiple stems (e.g., mixture, drums, bass, etc.).\n",
    "    Returns:\n",
    "        dataset_dict (dict): A dictionary where keys are track folders and values are dictionaries of stems.\n",
    "    \"\"\"\n",
    "\n",
    "    # sorted list of folders in the dataset\n",
    "    track_folders = sorted(\n",
    "        folder for folder in os.listdir(DATASET_FOLDER)\n",
    "        if os.path.isdir(os.path.join(DATASET_FOLDER, folder))\n",
    "    )\n",
    "\n",
    "    # Dictionary to store {track_folder -> {stem_name -> waveform}}\n",
    "    dataset_dict = {}\n",
    "\n",
    "    # Each subfolder in musdb18hq/test corresponds to a song\n",
    "    for track_folder in track_folders:\n",
    "        track_path = os.path.join(DATASET_FOLDER, track_folder)\n",
    "        if not os.path.isdir(track_path):\n",
    "            continue\n",
    "\n",
    "        # Prepare a sub-dictionary for this song\n",
    "        stems_dict = {}\n",
    "        stem_names = [\"mixture\", \"drums\", \"bass\", \"vocals\", \"other\"]\n",
    "        \n",
    "        for stem_name in stem_names:\n",
    "            file_path = os.path.abspath(os.path.join(track_path, f\"{stem_name}.wav\"))\n",
    "            \n",
    "            if not os.path.isfile(file_path):\n",
    "                print(f\"Warning: file not found {file_path}\")\n",
    "                continue\n",
    "\n",
    "            # Load full audio\n",
    "            print(f\"Loading {track_folder}\" + f\" - {stem_name}\")\n",
    "            waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "            stems_dict[stem_name] = waveform\n",
    "        \n",
    "        max_start = get_max_non_silence_start(stems_dict)\n",
    "\n",
    "        # If the stem is silent, remove it from the dictionary else trim it\n",
    "        for stem_name, waveform in stems_dict.items():\n",
    "            if is_stem_silent(waveform) or waveform.shape[1] < SEGMENT_LENGTH * sample_rate + max_start:\n",
    "                print(f\"Removing silent stem: {stem_name}\")\n",
    "                del stems_dict[stem_name]\n",
    "            else:\n",
    "                # Trim the waveform to the max_start to segment samples\n",
    "                duration = SEGMENT_LENGTH * sample_rate + max_start\n",
    "                stems_dict[stem_name] = waveform[:, max_start:duration]\n",
    "\n",
    "        dataset_dict[track_folder] = stems_dict\n",
    "\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Load the dataset from the musdb18hq_trimmed folder.\n",
    "    Each subfolder in the dataset corresponds to a song.\n",
    "    Each song contains multiple stems (e.g., mixture, drums, bass, etc.).\n",
    "    Returns:\n",
    "        dataset_dict (dict): A dictionary where keys are track folders and values are dictionaries of stems.\n",
    "    \"\"\"\n",
    "    dataset_dict = {}\n",
    "\n",
    "    for track_folder in os.listdir(\"musdb18hq_trimmed\"):\n",
    "        track_path = os.path.join(\"musdb18hq_trimmed\", track_folder)\n",
    "        if not os.path.isdir(track_path):\n",
    "            continue\n",
    "\n",
    "        # Prepare a sub-dictionary for this song\n",
    "        stems_dict = {}\n",
    "        \n",
    "        for stem_name in [\"mixture\", \"drums\", \"bass\", \"vocals\", \"other\", \"new_mixture\"]:\n",
    "            file_path = os.path.abspath(os.path.join(track_path, f\"{stem_name}.wav\"))\n",
    "            \n",
    "            if not os.path.isfile(file_path):\n",
    "                print(f\"Warning: file not found {file_path}\")\n",
    "                continue\n",
    "\n",
    "            # Load full audio\n",
    "            waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "            stems_dict[stem_name] = waveform\n",
    "            \n",
    "        dataset_dict[track_folder] = stems_dict\n",
    "        \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that creates the new mixture and save it in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_dict):\n",
    "    \"\"\"\n",
    "    Create a dataset of trimmed audio files from the musdb18hq dataset.\n",
    "    The dataset is saved in the musdb18hq_trimmed folder.\n",
    "    \"\"\"\n",
    "    for track_folder, stems_dict in dataset_dict.items():\n",
    "    \n",
    "        track_path = os.path.join(\"musdb18hq_trimmed\", track_folder)\n",
    "        os.makedirs(track_path, exist_ok=True)\n",
    "        \n",
    "        # Add new_mixture file to the track folder as the sum of the stems\n",
    "        new_mixture = torch.zeros((2, SEGMENT_LENGTH * sample_rate))\n",
    "        for stem_name, waveform in stems_dict.items():\n",
    "            \n",
    "            file_path = os.path.join(track_path, f\"{stem_name}.wav\")\n",
    "            torchaudio.save(file_path, waveform, sample_rate=sample_rate)\n",
    "\n",
    "            # Generation of the new_mixture file\n",
    "            if stem_name != \"mixture\":\n",
    "                new_mixture += waveform*0.25\n",
    "        \n",
    "        # Trim the new_mixture to the desired length\n",
    "        new_mixture = new_mixture[:, :SEGMENT_LENGTH * sample_rate]\n",
    "        new_mixture_path = os.path.join(track_path, \"new_mixture.wav\")\n",
    "        torchaudio.save(new_mixture_path, new_mixture, sample_rate)\n",
    "        #print(f\"Saved new mixture to {new_mixture_path}\")\n",
    "        \n",
    "        # Add the new_mixture to stems_dict and update dataset_dict\n",
    "        stems_dict[\"new_mixture\"] = new_mixture\n",
    "        dataset_dict[track_folder] = stems_dict  # Update the dataset_dict explicitly\n",
    "        #print(f\"Added new_mixture to stems_dict for track {track_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists.\n",
      "Dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(\"musdb18hq_trimmed\"):\n",
    "    print(\"Dataset already exists.\")\n",
    "    # Load the trimmed dataset\n",
    "    dataset_dict = load_dataset()\n",
    "    print(\"Dataset loaded.\")\n",
    "else:\n",
    "    print(\"Loading dataset...\")\n",
    "    dataset_dict = load_and_process_dataset()\n",
    "    print(\"Dataset loaded.\")\n",
    "    \n",
    "    # Save the trimmed dataset\n",
    "    os.makedirs(\"musdb18hq_trimmed\", exist_ok=True)\n",
    "    create_dataset(dataset_dict)\n",
    "\n",
    "    print(\"Trimmed dataset saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimmed tracks check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys in dataset_dict: 50\n",
      "First track folder: Moosmusic - Big Dummy Shake\n",
      "Contents of the first track folder:\n",
      " - mixture: torch.Size([2, 1323000])\n",
      " - drums: torch.Size([2, 1323000])\n",
      " - bass: torch.Size([2, 1323000])\n",
      " - vocals: torch.Size([2, 1323000])\n",
      " - other: torch.Size([2, 1323000])\n",
      " - new_mixture: torch.Size([2, 1323000])\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of keys in dataset_dict:\", len(dataset_dict))\n",
    "\n",
    "# Check the first track folder and its contents\n",
    "first_track_folder = list(dataset_dict.keys())[0]\n",
    "print(\"First track folder:\", first_track_folder)\n",
    "print(\"Contents of the first track folder:\")\n",
    "for stem_name in dataset_dict[first_track_folder].keys():\n",
    "    print(f\" - {stem_name}: {dataset_dict[first_track_folder][stem_name].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to separate the sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_sources(\n",
    "    model,\n",
    "    mix,\n",
    "    segment=30,\n",
    "    overlap=0.0,  # set to 0.0 to avoid chunk repetition\n",
    "    device=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply model to a given mixture. Use fade, and add segments together in order to add model segment by segment.\n",
    "\n",
    "    Args:\n",
    "        segment (int): segment length in seconds\n",
    "        device (torch.device, str, or None): if provided, device on which to\n",
    "            execute the computation, otherwise `mix.device` is assumed.\n",
    "            When `device` is different from `mix.device`, only local computations will\n",
    "            be on `device`, while the entire tracks will be stored on `mix.device`.\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = mix.device\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "\n",
    "    batch, channels, length = mix.shape\n",
    "\n",
    "    # chunk_len for entire 30s, no overlap\n",
    "    chunk_len = int(sample_rate * segment * (1 + overlap))  # effectively 30s if overlap=0\n",
    "    start = 0\n",
    "    end = chunk_len\n",
    "\n",
    "    overlap_frames = int(overlap * sample_rate)\n",
    "    fade = torchaudio.transforms.Fade(fade_in_len=0, fade_out_len=overlap_frames, fade_shape=\"linear\")\n",
    "\n",
    "    # Prepare final buffer\n",
    "    final = torch.zeros(batch, len(model.sources), channels, length, device=device)\n",
    "\n",
    "    while start < length - overlap_frames:\n",
    "        chunk = mix[:, :, start:end]\n",
    "        with torch.no_grad():\n",
    "        \n",
    "            # chunk = chunk.to(device)\n",
    "\n",
    "            out = model(chunk).to(device)\n",
    "            # out = out.to(device)\n",
    "            \n",
    "        out = fade(out)\n",
    "        final[:, :, :, start:end] += out\n",
    "\n",
    "        if start == 0:\n",
    "            fade.fade_in_len = overlap_frames\n",
    "            start += chunk_len - overlap_frames\n",
    "        else:\n",
    "            start += chunk_len\n",
    "        end += chunk_len\n",
    "        if end >= length:\n",
    "            fade.fade_out_len = 0\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the new DATASET FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataset folder\n",
    "DATASET_FOLDER_TRIMMED = \"./musdb18hq_trimmed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sdr(original_stem: torch.Tensor, predicted_stem: torch.Tensor, device: torch.device=None):\n",
    "    \"\"\"\n",
    "    Calculate the Scale-Invariant Signal-to-Distortion Ratio (SDR) between the original and predicted stems.\n",
    "\n",
    "    Args:\n",
    "        original_stem (torch.Tensor): The original stem waveform (shape: [channels, samples]).\n",
    "        predicted_stem (torch.Tensor): The predicted stem waveform (shape: [channels, samples]).\n",
    "\n",
    "    Returns:\n",
    "        float: The SDR value.\n",
    "    \"\"\"\n",
    "    # Ensure both tensors are on the same device\n",
    "    original_stem.to(device)\n",
    "    predicted_stem.to(device)\n",
    "    \n",
    "    # Initialize the SDR metric\n",
    "    sdr_metric = ScaleInvariantSignalDistortionRatio().to(device)\n",
    "\n",
    "    # Compute the SDR\n",
    "    sdr_value = sdr_metric(predicted_stem, original_stem).item()\n",
    "\n",
    "    return sdr_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the model in standard usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sdr_across_dataset(dataset_dict, model, segment_length, device):\n",
    "    \"\"\"\n",
    "    Separates and evaluates the SDR for each stem (bass, drums, vocals, other) across all tracks in the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_dict (dict): Dictionary containing the dataset with track folders and their stems.\n",
    "        model (torch.nn.Module): The source separation model.\n",
    "        segment_length (int): Length of the audio segment in seconds.\n",
    "        device (torch.device): The device to run the model on.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the average SDR for each stem.\n",
    "    \"\"\"\n",
    "    sdr_results = {stem: [] for stem in [\"bass\", \"drums\", \"vocals\", \"other\"]}\n",
    "\n",
    "    for track_name, stems_dict in dataset_dict.items():\n",
    "        print(f\"Processing track: {track_name}\")\n",
    "\n",
    "        # Ensure the mixture exists in the stems\n",
    "        if \"new_mixture\" not in stems_dict:\n",
    "            print(f\"Skipping track {track_name} as it does not contain a new mixture.\")\n",
    "            continue\n",
    "\n",
    "        # Load the mixture and move it to the correct device\n",
    "        mixture = stems_dict[\"new_mixture\"].to(device).unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        # Perform source separation\n",
    "        separated_sources = separate_sources(model, mixture, segment=segment_length, device=device)\n",
    "\n",
    "        # Evaluate SDR for each stem\n",
    "        for i, stem_name in enumerate(model.sources):\n",
    "            if stem_name in stems_dict:\n",
    "                original_stem = stems_dict[stem_name].to(device)\n",
    "                predicted_stem = separated_sources[0, i].to(device)\n",
    "\n",
    "                # Calculate SDR\n",
    "                sdr_value = evaluate_sdr(original_stem, predicted_stem, device=device)\n",
    "                sdr_results[stem_name].append(sdr_value)\n",
    "                print(f\"SDR for {stem_name} in track {track_name}: {sdr_value:.2f} dB\")\n",
    "\n",
    "    # Calculate the average SDR for each stem\n",
    "    average_sdr = {stem: (np.mean(values) if values else None) for stem, values in sdr_results.items()}\n",
    "\n",
    "    print(\"\\nAverage SDR for each stem:\")\n",
    "    for stem, avg_sdr in average_sdr.items():\n",
    "        print(f\"{stem}: {avg_sdr:.2f} dB\" if avg_sdr is not None else f\"{stem}: No data\")\n",
    "\n",
    "    return average_sdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the effect of the volume on the SDR on the same stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original stem shape: torch.Size([2, 1323000])\n",
      "Different volume stem shape: torch.Size([2, 1323000])\n",
      "SDR for original volume vs. itself: 105.44 dB\n",
      "SDR for different volume vs. original: 101.00 dB\n"
     ]
    }
   ],
   "source": [
    "track_names = list(dataset_dict.keys())\n",
    "\n",
    "track_chosen = track_names[25]\n",
    "\n",
    "# Retrieve the original \"new_mixture\" waveform from the specified track\n",
    "original_stem = dataset_dict[track_chosen][\"vocals\"]\n",
    "\n",
    "# Create a new version with a different volume \n",
    "different_vol_stem = original_stem * 0.6\n",
    "\n",
    "print(f\"Original stem shape: {original_stem.shape}\")\n",
    "print(f\"Different volume stem shape: {different_vol_stem.shape}\")\n",
    "\n",
    "# Evaluate SDR when comparing the original stem to itself \n",
    "sdr_original = evaluate_sdr(original_stem, original_stem)\n",
    "\n",
    "# Evaluate SDR when comparing the scaled stem to the original\n",
    "sdr_different = evaluate_sdr(original_stem, different_vol_stem)\n",
    "\n",
    "print(f\"SDR for original volume vs. itself: {sdr_original:.2f} dB\")\n",
    "print(f\"SDR for different volume vs. original: {sdr_different:.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to plot the average SDR across all the stems in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sdr_results(sdr_results):\n",
    "    \"\"\"\n",
    "    Plot the SDR results for each stem.\n",
    "\n",
    "    Args:\n",
    "        sdr_results (dict): Dictionary containing the average SDR for each stem.\n",
    "    \"\"\"\n",
    "    stems = list(sdr_results.keys())\n",
    "    sdr_values = [sdr_results[stem] for stem in stems]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(stems, sdr_values, color=['blue', 'orange', 'green', 'red'])\n",
    "    plt.xlabel('Stem')\n",
    "    plt.ylabel('Average SDR (dB)')\n",
    "    plt.title('Average SDR for Each Stem')\n",
    "    plt.ylim([0, max(sdr_values) + 5])\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: Moosmusic - Big Dummy Shake\n",
      "SDR for drums in track Moosmusic - Big Dummy Shake: 10.66 dB\n",
      "SDR for bass in track Moosmusic - Big Dummy Shake: 10.10 dB\n",
      "SDR for other in track Moosmusic - Big Dummy Shake: 7.11 dB\n",
      "SDR for vocals in track Moosmusic - Big Dummy Shake: 11.06 dB\n",
      "Processing track: The Mountaineering Club - Mallory\n",
      "SDR for drums in track The Mountaineering Club - Mallory: 14.67 dB\n",
      "SDR for bass in track The Mountaineering Club - Mallory: 10.87 dB\n",
      "SDR for other in track The Mountaineering Club - Mallory: 6.30 dB\n",
      "SDR for vocals in track The Mountaineering Club - Mallory: 13.20 dB\n",
      "Processing track: Bobby Nobody - Stitch Up\n",
      "SDR for drums in track Bobby Nobody - Stitch Up: 8.64 dB\n",
      "SDR for bass in track Bobby Nobody - Stitch Up: 9.46 dB\n",
      "SDR for other in track Bobby Nobody - Stitch Up: 5.80 dB\n",
      "SDR for vocals in track Bobby Nobody - Stitch Up: 10.13 dB\n",
      "Processing track: Punkdisco - Oral Hygiene\n",
      "SDR for drums in track Punkdisco - Oral Hygiene: 16.67 dB\n",
      "SDR for bass in track Punkdisco - Oral Hygiene: 17.22 dB\n",
      "SDR for other in track Punkdisco - Oral Hygiene: 5.28 dB\n",
      "SDR for vocals in track Punkdisco - Oral Hygiene: 9.40 dB\n",
      "Processing track: Lyndsey Ollard - Catching Up\n",
      "SDR for drums in track Lyndsey Ollard - Catching Up: 9.68 dB\n",
      "SDR for bass in track Lyndsey Ollard - Catching Up: 9.09 dB\n",
      "SDR for other in track Lyndsey Ollard - Catching Up: 9.00 dB\n",
      "SDR for vocals in track Lyndsey Ollard - Catching Up: 16.01 dB\n",
      "Processing track: Al James - Schoolboy Facination\n",
      "SDR for drums in track Al James - Schoolboy Facination: 7.68 dB\n",
      "SDR for bass in track Al James - Schoolboy Facination: 11.80 dB\n",
      "SDR for other in track Al James - Schoolboy Facination: 4.91 dB\n",
      "SDR for vocals in track Al James - Schoolboy Facination: 9.93 dB\n",
      "Processing track: James Elder & Mark M Thompson - The English Actor\n",
      "SDR for drums in track James Elder & Mark M Thompson - The English Actor: 8.07 dB\n",
      "SDR for bass in track James Elder & Mark M Thompson - The English Actor: 4.87 dB\n",
      "SDR for other in track James Elder & Mark M Thompson - The English Actor: 8.13 dB\n",
      "SDR for vocals in track James Elder & Mark M Thompson - The English Actor: 7.32 dB\n",
      "Processing track: Juliet's Rescue - Heartbeats\n",
      "SDR for drums in track Juliet's Rescue - Heartbeats: 20.28 dB\n",
      "SDR for bass in track Juliet's Rescue - Heartbeats: 2.03 dB\n",
      "SDR for other in track Juliet's Rescue - Heartbeats: 9.37 dB\n",
      "SDR for vocals in track Juliet's Rescue - Heartbeats: 11.19 dB\n",
      "Processing track: The Easton Ellises - Falcon 69\n",
      "SDR for drums in track The Easton Ellises - Falcon 69: 11.31 dB\n",
      "SDR for bass in track The Easton Ellises - Falcon 69: 9.04 dB\n",
      "SDR for other in track The Easton Ellises - Falcon 69: 5.09 dB\n",
      "SDR for vocals in track The Easton Ellises - Falcon 69: 7.03 dB\n",
      "Processing track: Secretariat - Borderline\n",
      "SDR for drums in track Secretariat - Borderline: 5.58 dB\n",
      "SDR for bass in track Secretariat - Borderline: 5.57 dB\n",
      "SDR for other in track Secretariat - Borderline: 7.19 dB\n",
      "SDR for vocals in track Secretariat - Borderline: 5.64 dB\n",
      "Processing track: The Long Wait - Dark Horses\n",
      "SDR for drums in track The Long Wait - Dark Horses: 10.22 dB\n",
      "SDR for bass in track The Long Wait - Dark Horses: 9.97 dB\n",
      "SDR for other in track The Long Wait - Dark Horses: 7.99 dB\n",
      "SDR for vocals in track The Long Wait - Dark Horses: 8.85 dB\n",
      "Processing track: Sambasevam Shanmugam - Kaathaadi\n",
      "SDR for drums in track Sambasevam Shanmugam - Kaathaadi: 13.77 dB\n",
      "SDR for bass in track Sambasevam Shanmugam - Kaathaadi: 15.38 dB\n",
      "SDR for other in track Sambasevam Shanmugam - Kaathaadi: 3.44 dB\n",
      "SDR for vocals in track Sambasevam Shanmugam - Kaathaadi: 12.64 dB\n",
      "Processing track: Signe Jakobsen - What Have You Done To Me\n",
      "SDR for drums in track Signe Jakobsen - What Have You Done To Me: 8.38 dB\n",
      "SDR for bass in track Signe Jakobsen - What Have You Done To Me: 6.92 dB\n",
      "SDR for other in track Signe Jakobsen - What Have You Done To Me: 6.39 dB\n",
      "SDR for vocals in track Signe Jakobsen - What Have You Done To Me: 11.75 dB\n",
      "Processing track: Girls Under Glass - We Feel Alright\n",
      "SDR for drums in track Girls Under Glass - We Feel Alright: 13.42 dB\n",
      "SDR for bass in track Girls Under Glass - We Feel Alright: 10.99 dB\n",
      "SDR for other in track Girls Under Glass - We Feel Alright: 8.07 dB\n",
      "SDR for vocals in track Girls Under Glass - We Feel Alright: 7.18 dB\n",
      "Processing track: Mu - Too Bright\n",
      "SDR for drums in track Mu - Too Bright: 17.42 dB\n",
      "SDR for bass in track Mu - Too Bright: 11.16 dB\n",
      "SDR for other in track Mu - Too Bright: 8.68 dB\n",
      "SDR for vocals in track Mu - Too Bright: 13.43 dB\n",
      "Processing track: Speak Softly - Broken Man\n",
      "SDR for drums in track Speak Softly - Broken Man: 12.70 dB\n",
      "SDR for bass in track Speak Softly - Broken Man: 22.04 dB\n",
      "SDR for other in track Speak Softly - Broken Man: 10.77 dB\n",
      "SDR for vocals in track Speak Softly - Broken Man: 6.53 dB\n",
      "Processing track: Georgia Wonder - Siren\n",
      "SDR for drums in track Georgia Wonder - Siren: 12.06 dB\n",
      "SDR for bass in track Georgia Wonder - Siren: 13.92 dB\n",
      "SDR for other in track Georgia Wonder - Siren: 6.75 dB\n",
      "SDR for vocals in track Georgia Wonder - Siren: 9.63 dB\n",
      "Processing track: Arise - Run Run Run\n",
      "SDR for drums in track Arise - Run Run Run: 12.76 dB\n",
      "SDR for bass in track Arise - Run Run Run: 13.64 dB\n",
      "SDR for other in track Arise - Run Run Run: 12.63 dB\n",
      "SDR for vocals in track Arise - Run Run Run: 11.80 dB\n",
      "Processing track: Raft Monk - Tiring\n",
      "SDR for drums in track Raft Monk - Tiring: 8.10 dB\n",
      "SDR for bass in track Raft Monk - Tiring: 8.44 dB\n",
      "SDR for other in track Raft Monk - Tiring: 2.76 dB\n",
      "SDR for vocals in track Raft Monk - Tiring: 4.11 dB\n",
      "Processing track: M.E.R.C. Music - Knockout\n",
      "SDR for drums in track M.E.R.C. Music - Knockout: 10.39 dB\n",
      "SDR for bass in track M.E.R.C. Music - Knockout: 13.64 dB\n",
      "SDR for other in track M.E.R.C. Music - Knockout: 6.16 dB\n",
      "SDR for vocals in track M.E.R.C. Music - Knockout: 9.45 dB\n",
      "Processing track: Triviul feat. The Fiend - Widow\n",
      "SDR for drums in track Triviul feat. The Fiend - Widow: 9.75 dB\n",
      "SDR for bass in track Triviul feat. The Fiend - Widow: 15.99 dB\n",
      "SDR for other in track Triviul feat. The Fiend - Widow: 2.75 dB\n",
      "SDR for vocals in track Triviul feat. The Fiend - Widow: 11.80 dB\n",
      "Processing track: Tom McKenzie - Directions\n",
      "SDR for drums in track Tom McKenzie - Directions: 16.17 dB\n",
      "SDR for bass in track Tom McKenzie - Directions: 7.33 dB\n",
      "SDR for other in track Tom McKenzie - Directions: 0.12 dB\n",
      "SDR for vocals in track Tom McKenzie - Directions: 9.89 dB\n",
      "Processing track: Timboz - Pony\n",
      "SDR for drums in track Timboz - Pony: 5.51 dB\n",
      "SDR for bass in track Timboz - Pony: 3.74 dB\n",
      "SDR for other in track Timboz - Pony: 8.92 dB\n",
      "SDR for vocals in track Timboz - Pony: 4.04 dB\n",
      "Processing track: BKS - Bulldozer\n",
      "SDR for drums in track BKS - Bulldozer: 14.88 dB\n",
      "SDR for bass in track BKS - Bulldozer: 11.92 dB\n",
      "SDR for other in track BKS - Bulldozer: 3.74 dB\n",
      "SDR for vocals in track BKS - Bulldozer: 14.69 dB\n",
      "Processing track: The Sunshine Garcia Band - For I Am The Moon\n",
      "SDR for drums in track The Sunshine Garcia Band - For I Am The Moon: 15.52 dB\n",
      "SDR for bass in track The Sunshine Garcia Band - For I Am The Moon: 15.24 dB\n",
      "SDR for other in track The Sunshine Garcia Band - For I Am The Moon: 8.33 dB\n",
      "SDR for vocals in track The Sunshine Garcia Band - For I Am The Moon: 11.34 dB\n",
      "Processing track: The Easton Ellises (Baumi) - SDRNR\n",
      "SDR for drums in track The Easton Ellises (Baumi) - SDRNR: 16.93 dB\n",
      "SDR for bass in track The Easton Ellises (Baumi) - SDRNR: 9.62 dB\n",
      "SDR for other in track The Easton Ellises (Baumi) - SDRNR: 7.25 dB\n",
      "SDR for vocals in track The Easton Ellises (Baumi) - SDRNR: 10.38 dB\n",
      "Processing track: AM Contra - Heart Peripheral\n",
      "SDR for drums in track AM Contra - Heart Peripheral: 10.19 dB\n",
      "SDR for bass in track AM Contra - Heart Peripheral: 4.13 dB\n",
      "SDR for other in track AM Contra - Heart Peripheral: 2.57 dB\n",
      "SDR for vocals in track AM Contra - Heart Peripheral: 11.41 dB\n",
      "Processing track: The Doppler Shift - Atrophy\n",
      "SDR for drums in track The Doppler Shift - Atrophy: 16.04 dB\n",
      "SDR for bass in track The Doppler Shift - Atrophy: 8.72 dB\n",
      "SDR for other in track The Doppler Shift - Atrophy: 10.30 dB\n",
      "SDR for vocals in track The Doppler Shift - Atrophy: 11.89 dB\n",
      "Processing track: Motor Tapes - Shore\n",
      "SDR for drums in track Motor Tapes - Shore: 9.51 dB\n",
      "SDR for bass in track Motor Tapes - Shore: 12.55 dB\n",
      "SDR for other in track Motor Tapes - Shore: 11.68 dB\n",
      "SDR for vocals in track Motor Tapes - Shore: 11.46 dB\n",
      "Processing track: Detsky Sad - Walkie Talkie\n",
      "SDR for drums in track Detsky Sad - Walkie Talkie: 11.61 dB\n",
      "SDR for bass in track Detsky Sad - Walkie Talkie: 6.04 dB\n",
      "SDR for other in track Detsky Sad - Walkie Talkie: 3.05 dB\n",
      "SDR for vocals in track Detsky Sad - Walkie Talkie: 11.62 dB\n",
      "Processing track: Buitraker - Revo X\n",
      "SDR for drums in track Buitraker - Revo X: 16.18 dB\n",
      "SDR for bass in track Buitraker - Revo X: 11.14 dB\n",
      "SDR for other in track Buitraker - Revo X: 5.10 dB\n",
      "SDR for vocals in track Buitraker - Revo X: 7.90 dB\n",
      "Processing track: Little Chicago's Finest - My Own\n",
      "SDR for drums in track Little Chicago's Finest - My Own: 19.05 dB\n",
      "SDR for bass in track Little Chicago's Finest - My Own: 16.65 dB\n",
      "SDR for other in track Little Chicago's Finest - My Own: 7.53 dB\n",
      "SDR for vocals in track Little Chicago's Finest - My Own: 13.67 dB\n",
      "Processing track: Zeno - Signs\n",
      "SDR for drums in track Zeno - Signs: 13.15 dB\n",
      "SDR for bass in track Zeno - Signs: 9.70 dB\n",
      "SDR for other in track Zeno - Signs: 8.07 dB\n",
      "SDR for vocals in track Zeno - Signs: 11.41 dB\n",
      "Processing track: Hollow Ground - Ill Fate\n",
      "SDR for drums in track Hollow Ground - Ill Fate: 6.08 dB\n",
      "SDR for bass in track Hollow Ground - Ill Fate: 3.26 dB\n",
      "SDR for other in track Hollow Ground - Ill Fate: 4.93 dB\n",
      "SDR for vocals in track Hollow Ground - Ill Fate: 6.41 dB\n",
      "Processing track: Cristina Vane - So Easy\n",
      "SDR for drums in track Cristina Vane - So Easy: 16.24 dB\n",
      "SDR for bass in track Cristina Vane - So Easy: 7.79 dB\n",
      "SDR for other in track Cristina Vane - So Easy: 4.47 dB\n",
      "SDR for vocals in track Cristina Vane - So Easy: 17.12 dB\n",
      "Processing track: Speak Softly - Like Horses\n",
      "SDR for drums in track Speak Softly - Like Horses: 8.16 dB\n",
      "SDR for bass in track Speak Softly - Like Horses: 24.76 dB\n",
      "SDR for other in track Speak Softly - Like Horses: 8.47 dB\n",
      "SDR for vocals in track Speak Softly - Like Horses: 8.47 dB\n",
      "Processing track: Side Effects Project - Sing With Me\n",
      "SDR for drums in track Side Effects Project - Sing With Me: 15.14 dB\n",
      "SDR for bass in track Side Effects Project - Sing With Me: 15.64 dB\n",
      "SDR for other in track Side Effects Project - Sing With Me: 4.82 dB\n",
      "SDR for vocals in track Side Effects Project - Sing With Me: 14.09 dB\n",
      "Processing track: Skelpolu - Resurrection\n",
      "SDR for drums in track Skelpolu - Resurrection: 10.57 dB\n",
      "SDR for bass in track Skelpolu - Resurrection: 14.85 dB\n",
      "SDR for other in track Skelpolu - Resurrection: 1.39 dB\n",
      "SDR for vocals in track Skelpolu - Resurrection: 2.60 dB\n",
      "Processing track: Nerve 9 - Pray For The Rain\n",
      "SDR for drums in track Nerve 9 - Pray For The Rain: 15.61 dB\n",
      "SDR for bass in track Nerve 9 - Pray For The Rain: 12.62 dB\n",
      "SDR for other in track Nerve 9 - Pray For The Rain: 8.36 dB\n",
      "SDR for vocals in track Nerve 9 - Pray For The Rain: 15.01 dB\n",
      "Processing track: Louis Cressy Band - Good Time\n",
      "SDR for drums in track Louis Cressy Band - Good Time: 11.06 dB\n",
      "SDR for bass in track Louis Cressy Band - Good Time: 9.82 dB\n",
      "SDR for other in track Louis Cressy Band - Good Time: 9.61 dB\n",
      "SDR for vocals in track Louis Cressy Band - Good Time: 11.39 dB\n",
      "Processing track: Angels In Amplifiers - I'm Alright\n",
      "SDR for drums in track Angels In Amplifiers - I'm Alright: 8.44 dB\n",
      "SDR for bass in track Angels In Amplifiers - I'm Alright: 11.63 dB\n",
      "SDR for other in track Angels In Amplifiers - I'm Alright: 7.74 dB\n",
      "SDR for vocals in track Angels In Amplifiers - I'm Alright: 11.96 dB\n",
      "Processing track: Ben Carrigan - We'll Talk About It All Tonight\n",
      "SDR for drums in track Ben Carrigan - We'll Talk About It All Tonight: 9.73 dB\n",
      "SDR for bass in track Ben Carrigan - We'll Talk About It All Tonight: 13.68 dB\n",
      "SDR for other in track Ben Carrigan - We'll Talk About It All Tonight: 3.69 dB\n",
      "SDR for vocals in track Ben Carrigan - We'll Talk About It All Tonight: 6.52 dB\n",
      "Processing track: BKS - Too Much\n",
      "SDR for drums in track BKS - Too Much: 11.34 dB\n",
      "SDR for bass in track BKS - Too Much: 14.48 dB\n",
      "SDR for other in track BKS - Too Much: 4.64 dB\n",
      "SDR for vocals in track BKS - Too Much: 15.02 dB\n",
      "Processing track: Carlos Gonzalez - A Place For Us\n",
      "SDR for drums in track Carlos Gonzalez - A Place For Us: 10.78 dB\n",
      "SDR for bass in track Carlos Gonzalez - A Place For Us: 9.77 dB\n",
      "SDR for other in track Carlos Gonzalez - A Place For Us: 7.97 dB\n",
      "SDR for vocals in track Carlos Gonzalez - A Place For Us: 10.54 dB\n",
      "Processing track: Secretariat - Over The Top\n",
      "SDR for drums in track Secretariat - Over The Top: 8.72 dB\n",
      "SDR for bass in track Secretariat - Over The Top: 13.12 dB\n",
      "SDR for other in track Secretariat - Over The Top: 6.03 dB\n",
      "SDR for vocals in track Secretariat - Over The Top: 9.00 dB\n",
      "Processing track: We Fell From The Sky - Not You\n",
      "SDR for drums in track We Fell From The Sky - Not You: 12.74 dB\n",
      "SDR for bass in track We Fell From The Sky - Not You: 4.73 dB\n",
      "SDR for other in track We Fell From The Sky - Not You: 8.59 dB\n",
      "SDR for vocals in track We Fell From The Sky - Not You: 7.20 dB\n",
      "Processing track: Enda Reilly - Cur An Long Ag Seol\n",
      "SDR for drums in track Enda Reilly - Cur An Long Ag Seol: 16.93 dB\n",
      "SDR for bass in track Enda Reilly - Cur An Long Ag Seol: 12.96 dB\n",
      "SDR for other in track Enda Reilly - Cur An Long Ag Seol: 9.02 dB\n",
      "SDR for vocals in track Enda Reilly - Cur An Long Ag Seol: 11.37 dB\n",
      "Processing track: Forkupines - Semantics\n",
      "SDR for drums in track Forkupines - Semantics: 13.06 dB\n",
      "SDR for bass in track Forkupines - Semantics: 5.36 dB\n",
      "SDR for other in track Forkupines - Semantics: 5.06 dB\n",
      "SDR for vocals in track Forkupines - Semantics: 9.61 dB\n",
      "Processing track: PR - Happy Daze\n",
      "SDR for drums in track PR - Happy Daze: 23.08 dB\n",
      "SDR for bass in track PR - Happy Daze: 20.41 dB\n",
      "SDR for other in track PR - Happy Daze: 11.33 dB\n",
      "SDR for vocals in track PR - Happy Daze: -1.47 dB\n",
      "Processing track: PR - Oh No\n",
      "SDR for drums in track PR - Oh No: 13.67 dB\n",
      "SDR for bass in track PR - Oh No: 13.42 dB\n",
      "SDR for other in track PR - Oh No: 5.96 dB\n",
      "SDR for vocals in track PR - Oh No: 5.16 dB\n",
      "\n",
      "Average SDR for each stem:\n",
      "bass: 11.14 dB\n",
      "drums: 12.37 dB\n",
      "vocals: 9.96 dB\n",
      "other: 6.67 dB\n",
      "Average SDR results per stem: {'bass': np.float64(11.143893756866454), 'drums': np.float64(12.365854654312134), 'vocals': np.float64(9.955585150718688), 'other': np.float64(6.666623520255089)}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SDR across the dataset using the provided function.\n",
    "average_sdr = evaluate_sdr_across_dataset(dataset_dict, model, SEGMENT_LENGTH, device)\n",
    "print(\"Average SDR results per stem:\", average_sdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the SDR results\n",
    "plot_sdr_results(average_sdr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maeCap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
