{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progressive Inference for Music Demixing ID: L12\n",
    "Description: Using denoising diffusion approaches to train music demixing (MDX) models is\n",
    "promising but requires retraining large and carefully tuned neural networks (Plaja-Roglans,\n",
    "2022). Instead, we will explore a related yet different approach: can we improve separation\n",
    "quality solely by scheduling the inference process using a diffusion-inspired strategy even\n",
    "without retraining? By experimenting with existing MDX models (Spleeter by Deezer,Meta’s Demucs, ByteDance’s BS-Roformer, etc.), this project offers an exciting opportunity\n",
    "to explore and possibly enhance the performance of state-of-the-art AI techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "\n",
    "\n",
    "(Plaja-Roglans, 2022) https://ismir2022program.ismir.net/poster_262.html\n",
    "Denoising Diffusion Probabilistic Models: https://arxiv.org/abs/2006.11239\n",
    "MDX Challenge 2021: https://arxiv.org/abs/2108.13559\n",
    "MDX Challenge 2023: https://arxiv.org/abs/2308.06979\n",
    "Overview of state-of-the-art MDX models:\n",
    "https://paperswithcode.com/sota/music-source-separation-on-musdb18-hq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary step: Install and Import Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: IPython in /opt/miniconda3/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (9.1.0)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.6.0)\n",
      "Requirement already satisfied: torchaudio in /opt/miniconda3/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.6.0)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2.2.5)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (3.10.1)\n",
      "Requirement already satisfied: librosa in /opt/miniconda3/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (0.11.0)\n",
      "Requirement already satisfied: torchmetrics in /opt/miniconda3/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (1.7.1)\n",
      "Requirement already satisfied: decorator in /opt/miniconda3/lib/python3.12/site-packages (from IPython->-r requirements.txt (line 1)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/miniconda3/lib/python3.12/site-packages (from IPython->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/miniconda3/lib/python3.12/site-packages (from IPython->-r requirements.txt (line 1)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/miniconda3/lib/python3.12/site-packages (from IPython->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/miniconda3/lib/python3.12/site-packages (from IPython->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/miniconda3/lib/python3.12/site-packages (from IPython->-r requirements.txt (line 1)) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/miniconda3/lib/python3.12/site-packages (from IPython->-r requirements.txt (line 1)) (2.15.1)\n",
      "Requirement already satisfied: stack_data in /opt/miniconda3/lib/python3.12/site-packages (from IPython->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/miniconda3/lib/python3.12/site-packages (from IPython->-r requirements.txt (line 1)) (5.14.3)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/miniconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda3/lib/python3.12/site-packages (from torch->-r requirements.txt (line 2)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/miniconda3/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 7)) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/miniconda3/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 7)) (0.61.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/miniconda3/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 7)) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 7)) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/miniconda3/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 7)) (1.4.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/miniconda3/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 7)) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/miniconda3/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 7)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/miniconda3/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 7)) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/miniconda3/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 7)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/miniconda3/lib/python3.12/site-packages (from librosa->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/miniconda3/lib/python3.12/site-packages (from torchmetrics->-r requirements.txt (line 8)) (0.14.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/miniconda3/lib/python3.12/site-packages (from jedi>=0.16->IPython->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/miniconda3/lib/python3.12/site-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 7)) (0.44.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/miniconda3/lib/python3.12/site-packages (from pexpect>4.3->IPython->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/miniconda3/lib/python3.12/site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 7)) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/miniconda3/lib/python3.12/site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 7)) (2.32.3)\n",
      "Requirement already satisfied: wcwidth in /opt/miniconda3/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->-r requirements.txt (line 1)) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from scikit-learn>=1.1.0->librosa->-r requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/miniconda3/lib/python3.12/site-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 7)) (1.17.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.12/site-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/miniconda3/lib/python3.12/site-packages (from stack_data->IPython->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/miniconda3/lib/python3.12/site-packages (from stack_data->IPython->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/miniconda3/lib/python3.12/site-packages (from stack_data->IPython->-r requirements.txt (line 1)) (0.2.3)\n",
      "Requirement already satisfied: pycparser in /opt/miniconda3/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 7)) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from torchmetrics.audio import ScaleInvariantSignalDistortionRatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of the Model and Device Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HDemucs(\n",
       "  (freq_encoder): ModuleList(\n",
       "    (0): _HEncLayer(\n",
       "      (conv): Conv2d(4, 48, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): _HEncLayer(\n",
       "      (conv): Conv2d(48, 96, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): _HEncLayer(\n",
       "      (conv): Conv2d(96, 192, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): _HEncLayer(\n",
       "      (conv): Conv2d(192, 384, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): _HEncLayer(\n",
       "      (conv): Conv2d(384, 768, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): _HEncLayer(\n",
       "      (conv): Conv1d(768, 1536, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv1d(1536, 3072, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (freq_decoder): ModuleList(\n",
       "    (0): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(1536, 768, kernel_size=(4,), stride=(2,))\n",
       "      (norm2): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv1d(1536, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (1): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(768, 384, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv2d(768, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (2): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(384, 192, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (3): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(192, 96, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (4): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(96, 48, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (5): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(48, 16, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "  )\n",
       "  (time_encoder): ModuleList(\n",
       "    (0): _HEncLayer(\n",
       "      (conv): Conv1d(2, 48, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(48, 96, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): _HEncLayer(\n",
       "      (conv): Conv1d(48, 96, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): _HEncLayer(\n",
       "      (conv): Conv1d(96, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): _HEncLayer(\n",
       "      (conv): Conv1d(192, 384, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): _HEncLayer(\n",
       "      (conv): Conv1d(384, 768, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Identity()\n",
       "      (norm2): Identity()\n",
       "      (dconv): Identity()\n",
       "    )\n",
       "  )\n",
       "  (time_decoder): ModuleList(\n",
       "    (0): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(768, 384, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
       "      (rewrite): Identity()\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (1): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(384, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (2): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(192, 96, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(192, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (3): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(96, 48, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(96, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (4): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(48, 8, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(48, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "  )\n",
       "  (freq_emb): _ScaledEmbedding(\n",
       "    (embedding): Embedding(512, 48)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundle = torchaudio.pipelines.HDEMUCS_HIGH_MUSDB_PLUS\n",
    "model = bundle.get_model()\n",
    "sample_rate = bundle.sample_rate\n",
    "\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # windows\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\") # macOS\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of the Dataset and Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset at: https://zenodo.org/records/3338373"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_LENGTH = 30  # 30 seconds of audio from each song\n",
    "DATASET_FOLDER =  \"./musdb18hq/test\" # dataset should be inside the project folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary creation\n",
    "\n",
    "(Dataset Structure: `{track_folder -> {stem_name -> waveform}`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_non_silence_start(song):\n",
    "    \"\"\"\n",
    "    Given a song (dictionary of stem names -> waveform),\n",
    "    use librosa.effects.trim to find the starting index of non-silent \n",
    "    segments for each stem and return the highest start index.\n",
    "    \"\"\"\n",
    "    max_start = 0\n",
    "    for stem, waveform in song.items():\n",
    "        # Convert tensor waveform to numpy if necessary\n",
    "        if hasattr(waveform, \"detach\"):\n",
    "            waveform_np = waveform.detach().cpu().numpy()\n",
    "        else:\n",
    "            waveform_np = waveform\n",
    "        \n",
    "        # If waveform is multi-channel (shape: channels x samples)\n",
    "        if waveform_np.ndim > 1:\n",
    "            # Convert to mono using librosa.to_mono\n",
    "            waveform_np = librosa.to_mono(waveform_np)\n",
    "        else:\n",
    "            waveform_np = waveform_np.squeeze()\n",
    "\n",
    "        # Trim leading and trailing silence\n",
    "        # trim returns a tuple (trimmed_audio, (start, end))\n",
    "        trimmed, indices = librosa.effects.trim(waveform_np)\n",
    "        if indices.size and indices[0] > max_start:\n",
    "            max_start = indices[0]\n",
    "            \n",
    "    return max_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stem_silent(waveform, threshold=1e-4):\n",
    "    \"\"\"\n",
    "    Determines if a given song stem is not silent.\n",
    "    \n",
    "    Args:\n",
    "        waveform (torch.Tensor or np.ndarray): The audio waveform of the stem.\n",
    "        threshold (float): The amplitude threshold below which the stem is considered silent.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the stem is not silent, False otherwise.\n",
    "    \"\"\"\n",
    "    # Convert tensor waveform to numpy if necessary\n",
    "    if hasattr(waveform, \"detach\"):\n",
    "        waveform = waveform.detach().cpu().numpy()\n",
    "    \n",
    "    # If waveform is multi-channel (shape: channels x samples), convert to mono\n",
    "    if waveform.ndim > 1:\n",
    "        waveform = librosa.to_mono(waveform)\n",
    "    \n",
    "    # Check if the maximum absolute amplitude exceeds the threshold\n",
    "    return np.max(np.abs(waveform)) < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_dataset():\n",
    "    \"\"\"\n",
    "    Load the dataset from the specified folder.\n",
    "    Each subfolder in the dataset corresponds to a song.\n",
    "    Each song contains multiple stems (e.g., mixture, drums, bass, etc.).\n",
    "    Returns:\n",
    "        dataset_dict (dict): A dictionary where keys are track folders and values are dictionaries of stems.\n",
    "    \"\"\"\n",
    "\n",
    "    # sorted list of folders in the dataset\n",
    "    track_folders = sorted(\n",
    "        folder for folder in os.listdir(DATASET_FOLDER)\n",
    "        if os.path.isdir(os.path.join(DATASET_FOLDER, folder))\n",
    "    )\n",
    "\n",
    "    # Dictionary to store {track_folder -> {stem_name -> waveform}}\n",
    "    dataset_dict = {}\n",
    "\n",
    "    # Each subfolder in musdb18hq/test corresponds to a song\n",
    "    for track_folder in tqdm.tqdm(track_folders):\n",
    "        track_path = os.path.join(DATASET_FOLDER, track_folder)\n",
    "        if not os.path.isdir(track_path):\n",
    "            continue\n",
    "\n",
    "        # Prepare a sub-dictionary for this song\n",
    "        stems_dict = {}\n",
    "        stem_names = [\"mixture\", \"drums\", \"bass\", \"vocals\", \"other\"]\n",
    "        \n",
    "        for stem_name in stem_names:\n",
    "            file_path = os.path.abspath(os.path.join(track_path, f\"{stem_name}.wav\"))\n",
    "            \n",
    "            if not os.path.isfile(file_path):\n",
    "                print(f\"Warning: file not found {file_path}\")\n",
    "                continue\n",
    "\n",
    "            # Load full audio\n",
    "            # print(f\"Loading {track_folder}\" + f\" - {stem_name}\")\n",
    "            waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "            stems_dict[stem_name] = waveform\n",
    "        \n",
    "        max_start = get_max_non_silence_start(stems_dict)\n",
    "\n",
    "        # If the stem is silent, remove it from the dictionary else trim it\n",
    "        for stem_name, waveform in stems_dict.items():\n",
    "            if is_stem_silent(waveform) or waveform.shape[1] < SEGMENT_LENGTH * sample_rate + max_start:\n",
    "                print(f\"Removing silent stem: {stem_name}\")\n",
    "                del stems_dict[stem_name]\n",
    "            else:\n",
    "                # Trim the waveform to the max_start to segment samples\n",
    "                duration = SEGMENT_LENGTH * sample_rate + max_start\n",
    "                stems_dict[stem_name] = waveform[:, max_start:duration]\n",
    "\n",
    "        dataset_dict[track_folder] = stems_dict\n",
    "\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Load the dataset from the musdb18hq_trimmed folder.\n",
    "    Each subfolder in the dataset corresponds to a song.\n",
    "    Each song contains multiple stems (e.g., mixture, drums, bass, etc.).\n",
    "    Returns:\n",
    "        dataset_dict (dict): A dictionary where keys are track folders and values are dictionaries of stems.\n",
    "    \"\"\"\n",
    "    dataset_dict = {}\n",
    "\n",
    "    for track_folder in tqdm.tqdm(os.listdir(\"musdb18hq_trimmed\")):\n",
    "        track_path = os.path.join(\"musdb18hq_trimmed\", track_folder)\n",
    "        if not os.path.isdir(track_path):\n",
    "            continue\n",
    "\n",
    "        # Prepare a sub-dictionary for this song\n",
    "        stems_dict = {}\n",
    "        \n",
    "        for stem_name in [\"mixture\", \"drums\", \"bass\", \"vocals\", \"other\", \"new_mixture\"]:\n",
    "            file_path = os.path.abspath(os.path.join(track_path, f\"{stem_name}.wav\"))\n",
    "            \n",
    "            if not os.path.isfile(file_path):\n",
    "                print(f\"Warning: file not found {file_path}\")\n",
    "                continue\n",
    "\n",
    "            # Load full audio\n",
    "            waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "            stems_dict[stem_name] = waveform\n",
    "            \n",
    "        dataset_dict[track_folder] = stems_dict\n",
    "        \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that creates the new mixture and save it in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_dict):\n",
    "    \"\"\"\n",
    "    Create a dataset of trimmed audio files from the musdb18hq dataset.\n",
    "    The dataset is saved in the musdb18hq_trimmed folder.\n",
    "    \"\"\"\n",
    "    for track_folder, stems_dict in tqdm.tqdm(dataset_dict.items()):\n",
    "    \n",
    "        track_path = os.path.join(\"musdb18hq_trimmed\", track_folder)\n",
    "        os.makedirs(track_path, exist_ok=True)\n",
    "        \n",
    "        # Add new_mixture file to the track folder as the sum of the stems\n",
    "        new_mixture = torch.zeros((2, SEGMENT_LENGTH * sample_rate))\n",
    "        for stem_name, waveform in stems_dict.items():\n",
    "            \n",
    "            file_path = os.path.join(track_path, f\"{stem_name}.wav\")\n",
    "            torchaudio.save(file_path, waveform, sample_rate=sample_rate)\n",
    "\n",
    "            # Generation of the new_mixture file\n",
    "            if stem_name != \"mixture\":\n",
    "                new_mixture += waveform*0.25\n",
    "\n",
    "        # Normalize the new_mixture to 1\n",
    "        new_mixture = new_mixture / torch.max(torch.abs(new_mixture))\n",
    "        \n",
    "        # Trim the new_mixture to the desired length\n",
    "        new_mixture = new_mixture[:, :SEGMENT_LENGTH * sample_rate]\n",
    "        new_mixture_path = os.path.join(track_path, \"new_mixture.wav\")\n",
    "        torchaudio.save(new_mixture_path, new_mixture, sample_rate)\n",
    "        #print(f\"Saved new mixture to {new_mixture_path}\")\n",
    "        \n",
    "        # Add the new_mixture to stems_dict and update dataset_dict\n",
    "        stems_dict[\"new_mixture\"] = new_mixture\n",
    "        dataset_dict[track_folder] = stems_dict  # Update the dataset_dict explicitly\n",
    "        #print(f\"Added new_mixture to stems_dict for track {track_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 148.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(\"musdb18hq_trimmed\"):\n",
    "    print(\"Dataset already exists.\")\n",
    "    # Load the trimmed dataset\n",
    "    dataset_dict = load_dataset()\n",
    "    print(\"Dataset loaded.\")\n",
    "else:\n",
    "    print(\"Loading dataset...\")\n",
    "    dataset_dict = load_and_process_dataset()\n",
    "    print(\"Dataset loaded.\")\n",
    "    \n",
    "    # Save the trimmed dataset\n",
    "    os.makedirs(\"musdb18hq_trimmed\", exist_ok=True)\n",
    "    create_dataset(dataset_dict)\n",
    "\n",
    "    print(\"Trimmed dataset saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimmed tracks check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys in dataset_dict: 50\n",
      "First track folder: Moosmusic - Big Dummy Shake\n",
      "Contents of the first track folder:\n",
      " - mixture: torch.Size([2, 1323000])\n",
      " - drums: torch.Size([2, 1323000])\n",
      " - bass: torch.Size([2, 1323000])\n",
      " - vocals: torch.Size([2, 1323000])\n",
      " - other: torch.Size([2, 1323000])\n",
      " - new_mixture: torch.Size([2, 1323000])\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of keys in dataset_dict:\", len(dataset_dict))\n",
    "\n",
    "# Check the first track folder and its contents\n",
    "first_track_folder = list(dataset_dict.keys())[0]\n",
    "print(\"First track folder:\", first_track_folder)\n",
    "print(\"Contents of the first track folder:\")\n",
    "for stem_name in dataset_dict[first_track_folder].keys():\n",
    "    print(f\" - {stem_name}: {dataset_dict[first_track_folder][stem_name].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to separate the sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_sources(\n",
    "    model,\n",
    "    mix,\n",
    "    sample_rate=sample_rate,\n",
    "    overlap=0.0,  # set to 0.0 to avoid chunk repetition\n",
    "    device=None,\n",
    "    normalize=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Separate sources from a mixture using the provided model.\n",
    "    Args:\n",
    "        model: The separation model.\n",
    "        mix: The input mixture tensor (batch, channels, length).\n",
    "        sample_rate: Sample rate of the audio.\n",
    "        overlap: Overlap between segments in seconds.\n",
    "        device: Device to run the model on (CPU or GPU).\n",
    "        normalize: Whether to normalize the input mixture.\n",
    "    Returns:\n",
    "        final: The separated sources tensor (batch, sources, channels, length).\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = mix.device\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "\n",
    "    batch, channels, length = mix.shape\n",
    "\n",
    "    # normalize the input by its RMS\n",
    "    if normalize:\n",
    "        # mix = mix / torch.sqrt(torch.mean(mix ** 2, dim=-1, keepdim=True))\n",
    "        mix = mix / torch.max(torch.abs(mix))\n",
    "\n",
    "    # chunk_len for entire 30s, no overlap\n",
    "    chunk_len = int(mix.shape[2] * (1 + overlap))  # effectively 30s if overlap=0\n",
    "    start = 0\n",
    "    end = chunk_len\n",
    "\n",
    "    overlap_frames = int(overlap * sample_rate)\n",
    "    fade = torchaudio.transforms.Fade(fade_in_len=0, fade_out_len=overlap_frames, fade_shape=\"linear\")\n",
    "\n",
    "    # Prepare final buffer\n",
    "    final = torch.zeros(batch, len(model.sources), channels, length, device=device)\n",
    "\n",
    "    while start < length - overlap_frames:\n",
    "        chunk = mix[:, :, start:end]\n",
    "        with torch.no_grad():\n",
    "            out = model(chunk).to(device)\n",
    "            \n",
    "        out = fade(out)\n",
    "        final[:, :, :, start:end] += out\n",
    "\n",
    "        if start == 0:\n",
    "            fade.fade_in_len = overlap_frames\n",
    "            start += chunk_len - overlap_frames\n",
    "        else:\n",
    "            start += chunk_len\n",
    "        end += chunk_len\n",
    "        if end >= length:\n",
    "            fade.fade_out_len = 0\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the new DATASET FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataset folder\n",
    "DATASET_FOLDER_TRIMMED = \"./musdb18hq_trimmed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sdr(original_stem: torch.Tensor, predicted_stem: torch.Tensor, device: torch.device=None):\n",
    "    \"\"\"\n",
    "    Calculate the Scale-Invariant Signal-to-Distortion Ratio (SDR) between the original and predicted stems.\n",
    "\n",
    "    Args:\n",
    "        original_stem (torch.Tensor): The original stem waveform (shape: [channels, samples]).\n",
    "        predicted_stem (torch.Tensor): The predicted stem waveform (shape: [channels, samples]).\n",
    "\n",
    "    Returns:\n",
    "        float: The SDR value.\n",
    "    \"\"\"\n",
    "    # Ensure both tensors are on the same device\n",
    "    original_stem.to(device)\n",
    "    predicted_stem.to(device)\n",
    "    \n",
    "    # Initialize the SDR metric\n",
    "    sdr_metric = ScaleInvariantSignalDistortionRatio().to(device)\n",
    "\n",
    "    # Compute the SDR\n",
    "    sdr_value = sdr_metric(predicted_stem, original_stem).item()\n",
    "\n",
    "    return sdr_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the model in standard usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sdr_across_dataset(dataset_dict, model, sample_rate, segment_length, device, normalize):\n",
    "    \"\"\"\n",
    "    Evaluate the SDR for each track in the dataset.\n",
    "    Args:\n",
    "        dataset_dict (dict): Dictionary containing the dataset.\n",
    "        model: The separation model.\n",
    "        sample_rate: Sample rate of the audio.\n",
    "        segment_length: Length of each segment in seconds.\n",
    "        device: Device to run the model on (CPU or GPU).\n",
    "        normalize: Whether to normalize the input mixture.\n",
    "    Returns:\n",
    "        average_sdr (dict): Dictionary containing the average SDR for each stem.\n",
    "    \"\"\"\n",
    "    sdr_results = {stem: [] for stem in [\"bass\", \"drums\", \"vocals\", \"other\"]}\n",
    "\n",
    "    for track_name, stems_dict in dataset_dict.items():\n",
    "        print(f\"Processing track: {track_name}\")\n",
    "\n",
    "        # Ensure the mixture exists in the stems\n",
    "        if \"new_mixture\" not in stems_dict:\n",
    "            print(f\"Skipping track {track_name} as it does not contain a new mixture.\")\n",
    "            continue\n",
    "\n",
    "        # Load the mixture and move it to the correct device\n",
    "        mixture = stems_dict[\"new_mixture\"].to(device).unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        # Perform source separation\n",
    "        separated_sources = separate_sources(model, mixture[:, :, :segment_length * sample_rate], sample_rate=sample_rate, device=device, normalize=normalize)\n",
    "\n",
    "        # Evaluate SDR for each stem\n",
    "        for i, stem_name in enumerate(model.sources):\n",
    "            if stem_name in stems_dict:\n",
    "                original_stem = stems_dict[stem_name].to(device)\n",
    "                predicted_stem = separated_sources[0, i].to(device)\n",
    "\n",
    "                # Calculate SDR\n",
    "                sdr_value = evaluate_sdr(original_stem, predicted_stem, device=device)\n",
    "                sdr_results[stem_name].append(sdr_value)\n",
    "                print(f\"SDR for {stem_name} in track {track_name}: {sdr_value:.2f} dB\")\n",
    "\n",
    "    # Calculate the average SDR for each stem\n",
    "    average_sdr = {stem: (np.mean(values) if values else None) for stem, values in sdr_results.items()}\n",
    "\n",
    "    print(\"\\nAverage SDR for each stem:\")\n",
    "    for stem, avg_sdr in average_sdr.items():\n",
    "        print(f\"{stem}: {avg_sdr:.2f} dB\" if avg_sdr is not None else f\"{stem}: No data\")\n",
    "\n",
    "    return average_sdr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the effect of the volume on the SDR on the same stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original stem shape: torch.Size([2, 1323000])\n",
      "Different volume stem shape: torch.Size([2, 1323000])\n",
      "SDR for original volume vs. itself: 105.44 dB\n",
      "SDR for different volume vs. original: 101.00 dB\n"
     ]
    }
   ],
   "source": [
    "track_names = list(dataset_dict.keys())\n",
    "\n",
    "track_chosen = track_names[25]\n",
    "\n",
    "# Retrieve the original \"new_mixture\" waveform from the specified track\n",
    "original_stem_test = dataset_dict[track_chosen][\"vocals\"]\n",
    "\n",
    "# Create a new version with a different volume \n",
    "different_vol_stem_test = original_stem_test * 0.6\n",
    "\n",
    "print(f\"Original stem shape: {original_stem_test.shape}\")\n",
    "print(f\"Different volume stem shape: {different_vol_stem_test.shape}\")\n",
    "\n",
    "# Evaluate SDR when comparing the original stem to itself \n",
    "sdr_original = evaluate_sdr(original_stem_test, original_stem_test)\n",
    "\n",
    "# Evaluate SDR when comparing the scaled stem to the original\n",
    "sdr_different = evaluate_sdr(original_stem_test, different_vol_stem_test)\n",
    "\n",
    "print(f\"SDR for original volume vs. itself: {sdr_original:.2f} dB\")\n",
    "print(f\"SDR for different volume vs. original: {sdr_different:.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to plot the average SDR across all the stems in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sdr_results(sdr_results):\n",
    "    \"\"\"\n",
    "    Plot the SDR results for each stem.\n",
    "\n",
    "    Args:\n",
    "        sdr_results (dict): Dictionary containing the average SDR for each stem.\n",
    "    \"\"\"\n",
    "    stems = list(sdr_results.keys())\n",
    "    sdr_values = [sdr_results[stem] for stem in stems]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(stems, sdr_values, color=['blue', 'orange', 'green', 'red'])\n",
    "    plt.xlabel('Stem')\n",
    "    plt.ylabel('Average SDR (dB)')\n",
    "    plt.title('Average SDR for Each Stem')\n",
    "    plt.ylim([0, max(sdr_values) + 5])\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track: Moosmusic - Big Dummy Shake\n",
      "SDR for drums in track Moosmusic - Big Dummy Shake: 10.66 dB\n",
      "SDR for bass in track Moosmusic - Big Dummy Shake: 10.10 dB\n",
      "SDR for other in track Moosmusic - Big Dummy Shake: 7.11 dB\n",
      "SDR for vocals in track Moosmusic - Big Dummy Shake: 11.06 dB\n",
      "Processing track: The Mountaineering Club - Mallory\n",
      "SDR for drums in track The Mountaineering Club - Mallory: 14.67 dB\n",
      "SDR for bass in track The Mountaineering Club - Mallory: 10.87 dB\n",
      "SDR for other in track The Mountaineering Club - Mallory: 6.30 dB\n",
      "SDR for vocals in track The Mountaineering Club - Mallory: 13.20 dB\n",
      "Processing track: Bobby Nobody - Stitch Up\n",
      "SDR for drums in track Bobby Nobody - Stitch Up: 8.64 dB\n",
      "SDR for bass in track Bobby Nobody - Stitch Up: 9.46 dB\n",
      "SDR for other in track Bobby Nobody - Stitch Up: 5.80 dB\n",
      "SDR for vocals in track Bobby Nobody - Stitch Up: 10.13 dB\n",
      "Processing track: Punkdisco - Oral Hygiene\n",
      "SDR for drums in track Punkdisco - Oral Hygiene: 16.67 dB\n",
      "SDR for bass in track Punkdisco - Oral Hygiene: 17.22 dB\n",
      "SDR for other in track Punkdisco - Oral Hygiene: 5.28 dB\n",
      "SDR for vocals in track Punkdisco - Oral Hygiene: 9.40 dB\n",
      "Processing track: Lyndsey Ollard - Catching Up\n",
      "SDR for drums in track Lyndsey Ollard - Catching Up: 9.68 dB\n",
      "SDR for bass in track Lyndsey Ollard - Catching Up: 9.09 dB\n",
      "SDR for other in track Lyndsey Ollard - Catching Up: 9.00 dB\n",
      "SDR for vocals in track Lyndsey Ollard - Catching Up: 16.01 dB\n",
      "Processing track: Al James - Schoolboy Facination\n",
      "SDR for drums in track Al James - Schoolboy Facination: 7.68 dB\n",
      "SDR for bass in track Al James - Schoolboy Facination: 11.80 dB\n",
      "SDR for other in track Al James - Schoolboy Facination: 4.91 dB\n",
      "SDR for vocals in track Al James - Schoolboy Facination: 9.93 dB\n",
      "Processing track: James Elder & Mark M Thompson - The English Actor\n",
      "SDR for drums in track James Elder & Mark M Thompson - The English Actor: 8.07 dB\n",
      "SDR for bass in track James Elder & Mark M Thompson - The English Actor: 4.87 dB\n",
      "SDR for other in track James Elder & Mark M Thompson - The English Actor: 8.13 dB\n",
      "SDR for vocals in track James Elder & Mark M Thompson - The English Actor: 7.32 dB\n",
      "Processing track: Juliet's Rescue - Heartbeats\n",
      "SDR for drums in track Juliet's Rescue - Heartbeats: 20.27 dB\n",
      "SDR for bass in track Juliet's Rescue - Heartbeats: 2.20 dB\n",
      "SDR for other in track Juliet's Rescue - Heartbeats: 9.40 dB\n",
      "SDR for vocals in track Juliet's Rescue - Heartbeats: 11.15 dB\n",
      "Processing track: The Easton Ellises - Falcon 69\n",
      "SDR for drums in track The Easton Ellises - Falcon 69: 11.31 dB\n",
      "SDR for bass in track The Easton Ellises - Falcon 69: 9.04 dB\n",
      "SDR for other in track The Easton Ellises - Falcon 69: 5.09 dB\n",
      "SDR for vocals in track The Easton Ellises - Falcon 69: 7.03 dB\n",
      "Processing track: Secretariat - Borderline\n",
      "SDR for drums in track Secretariat - Borderline: 5.58 dB\n",
      "SDR for bass in track Secretariat - Borderline: 5.57 dB\n",
      "SDR for other in track Secretariat - Borderline: 7.19 dB\n",
      "SDR for vocals in track Secretariat - Borderline: 5.64 dB\n",
      "Processing track: The Long Wait - Dark Horses\n",
      "SDR for drums in track The Long Wait - Dark Horses: 10.22 dB\n",
      "SDR for bass in track The Long Wait - Dark Horses: 9.97 dB\n",
      "SDR for other in track The Long Wait - Dark Horses: 7.99 dB\n",
      "SDR for vocals in track The Long Wait - Dark Horses: 8.85 dB\n",
      "Processing track: Sambasevam Shanmugam - Kaathaadi\n",
      "SDR for drums in track Sambasevam Shanmugam - Kaathaadi: 13.77 dB\n",
      "SDR for bass in track Sambasevam Shanmugam - Kaathaadi: 15.38 dB\n",
      "SDR for other in track Sambasevam Shanmugam - Kaathaadi: 3.44 dB\n",
      "SDR for vocals in track Sambasevam Shanmugam - Kaathaadi: 12.64 dB\n",
      "Processing track: Signe Jakobsen - What Have You Done To Me\n",
      "SDR for drums in track Signe Jakobsen - What Have You Done To Me: 8.38 dB\n",
      "SDR for bass in track Signe Jakobsen - What Have You Done To Me: 6.92 dB\n",
      "SDR for other in track Signe Jakobsen - What Have You Done To Me: 6.39 dB\n",
      "SDR for vocals in track Signe Jakobsen - What Have You Done To Me: 11.75 dB\n",
      "Processing track: Girls Under Glass - We Feel Alright\n",
      "SDR for drums in track Girls Under Glass - We Feel Alright: 13.42 dB\n",
      "SDR for bass in track Girls Under Glass - We Feel Alright: 10.99 dB\n",
      "SDR for other in track Girls Under Glass - We Feel Alright: 8.07 dB\n",
      "SDR for vocals in track Girls Under Glass - We Feel Alright: 7.18 dB\n",
      "Processing track: Mu - Too Bright\n",
      "SDR for drums in track Mu - Too Bright: 17.42 dB\n",
      "SDR for bass in track Mu - Too Bright: 11.16 dB\n",
      "SDR for other in track Mu - Too Bright: 8.68 dB\n",
      "SDR for vocals in track Mu - Too Bright: 13.43 dB\n",
      "Processing track: Speak Softly - Broken Man\n",
      "SDR for drums in track Speak Softly - Broken Man: 12.69 dB\n",
      "SDR for bass in track Speak Softly - Broken Man: 22.05 dB\n",
      "SDR for other in track Speak Softly - Broken Man: 10.77 dB\n",
      "SDR for vocals in track Speak Softly - Broken Man: 6.52 dB\n",
      "Processing track: Georgia Wonder - Siren\n",
      "SDR for drums in track Georgia Wonder - Siren: 12.10 dB\n",
      "SDR for bass in track Georgia Wonder - Siren: 14.01 dB\n",
      "SDR for other in track Georgia Wonder - Siren: 6.75 dB\n",
      "SDR for vocals in track Georgia Wonder - Siren: 9.64 dB\n",
      "Processing track: Arise - Run Run Run\n",
      "SDR for drums in track Arise - Run Run Run: 12.76 dB\n",
      "SDR for bass in track Arise - Run Run Run: 13.64 dB\n",
      "SDR for other in track Arise - Run Run Run: 12.63 dB\n",
      "SDR for vocals in track Arise - Run Run Run: 11.80 dB\n",
      "Processing track: Raft Monk - Tiring\n",
      "SDR for drums in track Raft Monk - Tiring: 8.10 dB\n",
      "SDR for bass in track Raft Monk - Tiring: 8.44 dB\n",
      "SDR for other in track Raft Monk - Tiring: 2.76 dB\n",
      "SDR for vocals in track Raft Monk - Tiring: 4.11 dB\n",
      "Processing track: M.E.R.C. Music - Knockout\n",
      "SDR for drums in track M.E.R.C. Music - Knockout: 10.39 dB\n",
      "SDR for bass in track M.E.R.C. Music - Knockout: 13.64 dB\n",
      "SDR for other in track M.E.R.C. Music - Knockout: 6.16 dB\n",
      "SDR for vocals in track M.E.R.C. Music - Knockout: 9.45 dB\n",
      "Processing track: Triviul feat. The Fiend - Widow\n",
      "SDR for drums in track Triviul feat. The Fiend - Widow: 9.75 dB\n",
      "SDR for bass in track Triviul feat. The Fiend - Widow: 15.99 dB\n",
      "SDR for other in track Triviul feat. The Fiend - Widow: 2.74 dB\n",
      "SDR for vocals in track Triviul feat. The Fiend - Widow: 11.80 dB\n",
      "Processing track: Tom McKenzie - Directions\n",
      "SDR for drums in track Tom McKenzie - Directions: 16.17 dB\n",
      "SDR for bass in track Tom McKenzie - Directions: 7.33 dB\n",
      "SDR for other in track Tom McKenzie - Directions: 0.12 dB\n",
      "SDR for vocals in track Tom McKenzie - Directions: 9.89 dB\n",
      "Processing track: Timboz - Pony\n",
      "SDR for drums in track Timboz - Pony: 5.51 dB\n",
      "SDR for bass in track Timboz - Pony: 3.74 dB\n",
      "SDR for other in track Timboz - Pony: 8.92 dB\n",
      "SDR for vocals in track Timboz - Pony: 4.04 dB\n",
      "Processing track: BKS - Bulldozer\n",
      "SDR for drums in track BKS - Bulldozer: 14.88 dB\n",
      "SDR for bass in track BKS - Bulldozer: 11.92 dB\n",
      "SDR for other in track BKS - Bulldozer: 3.74 dB\n",
      "SDR for vocals in track BKS - Bulldozer: 14.69 dB\n",
      "Processing track: The Sunshine Garcia Band - For I Am The Moon\n",
      "SDR for drums in track The Sunshine Garcia Band - For I Am The Moon: 15.52 dB\n",
      "SDR for bass in track The Sunshine Garcia Band - For I Am The Moon: 15.24 dB\n",
      "SDR for other in track The Sunshine Garcia Band - For I Am The Moon: 8.33 dB\n",
      "SDR for vocals in track The Sunshine Garcia Band - For I Am The Moon: 11.34 dB\n",
      "Processing track: The Easton Ellises (Baumi) - SDRNR\n",
      "SDR for drums in track The Easton Ellises (Baumi) - SDRNR: 16.93 dB\n",
      "SDR for bass in track The Easton Ellises (Baumi) - SDRNR: 9.62 dB\n",
      "SDR for other in track The Easton Ellises (Baumi) - SDRNR: 7.25 dB\n",
      "SDR for vocals in track The Easton Ellises (Baumi) - SDRNR: 10.38 dB\n",
      "Processing track: AM Contra - Heart Peripheral\n",
      "SDR for drums in track AM Contra - Heart Peripheral: 10.19 dB\n",
      "SDR for bass in track AM Contra - Heart Peripheral: 4.13 dB\n",
      "SDR for other in track AM Contra - Heart Peripheral: 2.57 dB\n",
      "SDR for vocals in track AM Contra - Heart Peripheral: 11.41 dB\n",
      "Processing track: The Doppler Shift - Atrophy\n",
      "SDR for drums in track The Doppler Shift - Atrophy: 16.04 dB\n",
      "SDR for bass in track The Doppler Shift - Atrophy: 8.72 dB\n",
      "SDR for other in track The Doppler Shift - Atrophy: 10.30 dB\n",
      "SDR for vocals in track The Doppler Shift - Atrophy: 11.89 dB\n",
      "Processing track: Motor Tapes - Shore\n",
      "SDR for drums in track Motor Tapes - Shore: 9.51 dB\n",
      "SDR for bass in track Motor Tapes - Shore: 12.55 dB\n",
      "SDR for other in track Motor Tapes - Shore: 11.68 dB\n",
      "SDR for vocals in track Motor Tapes - Shore: 11.46 dB\n",
      "Processing track: Detsky Sad - Walkie Talkie\n",
      "SDR for drums in track Detsky Sad - Walkie Talkie: 11.61 dB\n",
      "SDR for bass in track Detsky Sad - Walkie Talkie: 6.04 dB\n",
      "SDR for other in track Detsky Sad - Walkie Talkie: 3.05 dB\n",
      "SDR for vocals in track Detsky Sad - Walkie Talkie: 11.62 dB\n",
      "Processing track: Buitraker - Revo X\n",
      "SDR for drums in track Buitraker - Revo X: 16.18 dB\n",
      "SDR for bass in track Buitraker - Revo X: 11.14 dB\n",
      "SDR for other in track Buitraker - Revo X: 5.10 dB\n",
      "SDR for vocals in track Buitraker - Revo X: 7.90 dB\n",
      "Processing track: Little Chicago's Finest - My Own\n",
      "SDR for drums in track Little Chicago's Finest - My Own: 19.05 dB\n",
      "SDR for bass in track Little Chicago's Finest - My Own: 16.65 dB\n",
      "SDR for other in track Little Chicago's Finest - My Own: 7.53 dB\n",
      "SDR for vocals in track Little Chicago's Finest - My Own: 13.67 dB\n",
      "Processing track: Zeno - Signs\n",
      "SDR for drums in track Zeno - Signs: 13.15 dB\n",
      "SDR for bass in track Zeno - Signs: 9.70 dB\n",
      "SDR for other in track Zeno - Signs: 8.07 dB\n",
      "SDR for vocals in track Zeno - Signs: 11.41 dB\n",
      "Processing track: Hollow Ground - Ill Fate\n",
      "SDR for drums in track Hollow Ground - Ill Fate: 6.08 dB\n",
      "SDR for bass in track Hollow Ground - Ill Fate: 3.26 dB\n",
      "SDR for other in track Hollow Ground - Ill Fate: 4.93 dB\n",
      "SDR for vocals in track Hollow Ground - Ill Fate: 6.41 dB\n",
      "Processing track: Cristina Vane - So Easy\n",
      "SDR for drums in track Cristina Vane - So Easy: 16.24 dB\n",
      "SDR for bass in track Cristina Vane - So Easy: 7.79 dB\n",
      "SDR for other in track Cristina Vane - So Easy: 4.47 dB\n",
      "SDR for vocals in track Cristina Vane - So Easy: 17.12 dB\n",
      "Processing track: Speak Softly - Like Horses\n",
      "SDR for drums in track Speak Softly - Like Horses: 8.16 dB\n",
      "SDR for bass in track Speak Softly - Like Horses: 24.76 dB\n",
      "SDR for other in track Speak Softly - Like Horses: 8.47 dB\n",
      "SDR for vocals in track Speak Softly - Like Horses: 8.47 dB\n",
      "Processing track: Side Effects Project - Sing With Me\n",
      "SDR for drums in track Side Effects Project - Sing With Me: 15.14 dB\n",
      "SDR for bass in track Side Effects Project - Sing With Me: 15.64 dB\n",
      "SDR for other in track Side Effects Project - Sing With Me: 4.82 dB\n",
      "SDR for vocals in track Side Effects Project - Sing With Me: 14.09 dB\n",
      "Processing track: Skelpolu - Resurrection\n",
      "SDR for drums in track Skelpolu - Resurrection: 10.57 dB\n",
      "SDR for bass in track Skelpolu - Resurrection: 14.85 dB\n",
      "SDR for other in track Skelpolu - Resurrection: 1.39 dB\n",
      "SDR for vocals in track Skelpolu - Resurrection: 2.60 dB\n",
      "Processing track: Nerve 9 - Pray For The Rain\n",
      "SDR for drums in track Nerve 9 - Pray For The Rain: 15.61 dB\n",
      "SDR for bass in track Nerve 9 - Pray For The Rain: 12.62 dB\n",
      "SDR for other in track Nerve 9 - Pray For The Rain: 8.36 dB\n",
      "SDR for vocals in track Nerve 9 - Pray For The Rain: 15.01 dB\n",
      "Processing track: Louis Cressy Band - Good Time\n",
      "SDR for drums in track Louis Cressy Band - Good Time: 11.06 dB\n",
      "SDR for bass in track Louis Cressy Band - Good Time: 9.82 dB\n",
      "SDR for other in track Louis Cressy Band - Good Time: 9.61 dB\n",
      "SDR for vocals in track Louis Cressy Band - Good Time: 11.39 dB\n",
      "Processing track: Angels In Amplifiers - I'm Alright\n",
      "SDR for drums in track Angels In Amplifiers - I'm Alright: 8.44 dB\n",
      "SDR for bass in track Angels In Amplifiers - I'm Alright: 11.63 dB\n",
      "SDR for other in track Angels In Amplifiers - I'm Alright: 7.74 dB\n",
      "SDR for vocals in track Angels In Amplifiers - I'm Alright: 11.96 dB\n",
      "Processing track: Ben Carrigan - We'll Talk About It All Tonight\n",
      "SDR for drums in track Ben Carrigan - We'll Talk About It All Tonight: 9.73 dB\n",
      "SDR for bass in track Ben Carrigan - We'll Talk About It All Tonight: 13.68 dB\n",
      "SDR for other in track Ben Carrigan - We'll Talk About It All Tonight: 3.69 dB\n",
      "SDR for vocals in track Ben Carrigan - We'll Talk About It All Tonight: 6.52 dB\n",
      "Processing track: BKS - Too Much\n",
      "SDR for drums in track BKS - Too Much: 11.34 dB\n",
      "SDR for bass in track BKS - Too Much: 14.48 dB\n",
      "SDR for other in track BKS - Too Much: 4.64 dB\n",
      "SDR for vocals in track BKS - Too Much: 15.02 dB\n",
      "Processing track: Carlos Gonzalez - A Place For Us\n",
      "SDR for drums in track Carlos Gonzalez - A Place For Us: 10.78 dB\n",
      "SDR for bass in track Carlos Gonzalez - A Place For Us: 9.77 dB\n",
      "SDR for other in track Carlos Gonzalez - A Place For Us: 7.97 dB\n",
      "SDR for vocals in track Carlos Gonzalez - A Place For Us: 10.54 dB\n",
      "Processing track: Secretariat - Over The Top\n",
      "SDR for drums in track Secretariat - Over The Top: 8.72 dB\n",
      "SDR for bass in track Secretariat - Over The Top: 13.12 dB\n",
      "SDR for other in track Secretariat - Over The Top: 6.03 dB\n",
      "SDR for vocals in track Secretariat - Over The Top: 9.00 dB\n",
      "Processing track: We Fell From The Sky - Not You\n",
      "SDR for drums in track We Fell From The Sky - Not You: 12.74 dB\n",
      "SDR for bass in track We Fell From The Sky - Not You: 4.73 dB\n",
      "SDR for other in track We Fell From The Sky - Not You: 8.59 dB\n",
      "SDR for vocals in track We Fell From The Sky - Not You: 7.20 dB\n",
      "Processing track: Enda Reilly - Cur An Long Ag Seol\n",
      "SDR for drums in track Enda Reilly - Cur An Long Ag Seol: 16.93 dB\n",
      "SDR for bass in track Enda Reilly - Cur An Long Ag Seol: 12.96 dB\n",
      "SDR for other in track Enda Reilly - Cur An Long Ag Seol: 9.02 dB\n",
      "SDR for vocals in track Enda Reilly - Cur An Long Ag Seol: 11.37 dB\n",
      "Processing track: Forkupines - Semantics\n",
      "SDR for drums in track Forkupines - Semantics: 13.06 dB\n",
      "SDR for bass in track Forkupines - Semantics: 5.36 dB\n",
      "SDR for other in track Forkupines - Semantics: 5.06 dB\n",
      "SDR for vocals in track Forkupines - Semantics: 9.61 dB\n",
      "Processing track: PR - Happy Daze\n",
      "SDR for drums in track PR - Happy Daze: 23.08 dB\n",
      "SDR for bass in track PR - Happy Daze: 20.41 dB\n",
      "SDR for other in track PR - Happy Daze: 11.33 dB\n",
      "SDR for vocals in track PR - Happy Daze: -1.47 dB\n",
      "Processing track: PR - Oh No\n",
      "SDR for drums in track PR - Oh No: 13.67 dB\n",
      "SDR for bass in track PR - Oh No: 13.42 dB\n",
      "SDR for other in track PR - Oh No: 5.96 dB\n",
      "SDR for vocals in track PR - Oh No: 5.16 dB\n",
      "\n",
      "Average SDR for each stem:\n",
      "bass: 11.15 dB\n",
      "drums: 12.37 dB\n",
      "vocals: 9.95 dB\n",
      "other: 6.67 dB\n",
      "Average SDR results per stem: {'bass': np.float64(11.149303317070007), 'drums': np.float64(12.366251049041749), 'vocals': np.float64(9.954828152656555), 'other': np.float64(6.667282370477915)}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SDR across the dataset using the provided function using no normalization.\n",
    "average_sdr = evaluate_sdr_across_dataset(dataset_dict, model, sample_rate, SEGMENT_LENGTH, device, normalize=False)\n",
    "print(\"Average SDR results per stem:\", average_sdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the SDR results\n",
    "plot_sdr_results(average_sdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from an Oracle Predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(initial_gains, step, steps, target_stem, schedule_type):\n",
    "    \"\"\"\n",
    "    Create a schedule for the target stem's gain based on the specified schedule type.\n",
    "\n",
    "    Args:\n",
    "        initial_gains (dict): Dictionary of initial gains for each stem.\n",
    "        step (int): The current step in the schedule.\n",
    "        steps (int): The total number of steps in the schedule.\n",
    "        target_stem (str): The stem to which the schedule is applied.\n",
    "        schedule_type (str): The type of schedule ('linear', 'exponential', or 'constant').\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated gains for each stem.\n",
    "    \"\"\"\n",
    "    if schedule_type == \"linear\":\n",
    "        # Linear \n",
    "        decay = initial_gains[target_stem] * (1 + step / steps)\n",
    "    elif schedule_type == \"exponential\":\n",
    "        # Exponential decay\n",
    "        decay = initial_gains[target_stem] * np.exp(step / steps)\n",
    "    elif schedule_type == \"constant\":\n",
    "        # Constant gain\n",
    "        decay = initial_gains[target_stem]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid schedule type. Choose from 'linear', 'exponential', or 'constant'.\")\n",
    "\n",
    "    # Update the target stem's gain\n",
    "    updated_gains = initial_gains.copy()\n",
    "    updated_gains[target_stem] = decay\n",
    "\n",
    "    # Normalize the gains\n",
    "    total_gain = sum(updated_gains.values())\n",
    "    for stem in updated_gains:\n",
    "        updated_gains[stem] /= total_gain\n",
    "\n",
    "    return updated_gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressive_inference(\n",
    "    model,\n",
    "    mix,\n",
    "    target_stem,\n",
    "    reference_stem,\n",
    "    initial_gains,\n",
    "    sample_rate,\n",
    "    overlap=0.0, \n",
    "    device=None,\n",
    "    normalize=True,\n",
    "    steps=10,\n",
    "    schedule_type=\"linear\",\n",
    "    checkSDREachStep=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform progressive inference on the mixture using the specified model and schedule.\n",
    "    Args:\n",
    "        model: The separation model.\n",
    "        mix: The input mixture tensor (batch, channels, length).\n",
    "        target_stem: The target stem to be enhanced.\n",
    "        initial_gains: Initial gains for each stem.\n",
    "        sample_rate: Sample rate of the audio.\n",
    "        overlap: Overlap between segments in seconds.\n",
    "        device: Device to run the model on (CPU or GPU).\n",
    "        normalize: Whether to normalize the input mixture.\n",
    "        steps: Number of steps for progressive inference.\n",
    "        schedule_type: Type of schedule ('linear', 'exponential', or 'constant').\n",
    "    Returns:\n",
    "        separated_sources: The separated sources tensor (batch, sources, channels, length).\n",
    "        sdr_results: Dictionary containing SDR results for each stem.\n",
    "    \"\"\"\n",
    "\n",
    "    sdr_results = {stem: [] for stem in [\"bass\", \"drums\", \"vocals\", \"other\"]}\n",
    "\n",
    "    if device is None:\n",
    "        device = mix.device\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "\n",
    "    #batch, channels, length = mix.shape\n",
    "\n",
    "    separated_sources = separate_sources(model, mix, sample_rate=sample_rate, overlap=overlap, device=device, normalize=normalize)\n",
    "\n",
    "    if(checkSDREachStep):\n",
    "        for i, stem_name in enumerate(model.sources):\n",
    "            original_stem = reference_stem.to(device)\n",
    "            predicted_stem = separated_sources[0, i].to(device)\n",
    "\n",
    "            # Calculate SDR\n",
    "            sdr_value = evaluate_sdr(original_stem, predicted_stem, device=device)\n",
    "\n",
    "            # save the SDR value in a dictionary\n",
    "            sdr_results[stem_name].append(sdr_value)\n",
    "    \n",
    "    # Print the volume of the separated sources\n",
    "    for i in range(4):\n",
    "        print(\"Separated sources volume:\", separated_sources[0, i].max())\n",
    "\n",
    "    print(\"Initial SDR: \", sdr_results)\n",
    "\n",
    "    # Listen to the separated sources\n",
    "    for i in range(4):\n",
    "        print(\"Separated source: \", i)\n",
    "        # Play the separated source\n",
    "        IPython.display.Audio(separated_sources[0, i].cpu(), rate=sample_rate)\n",
    "        \n",
    "\n",
    "    return None, None\n",
    "    \n",
    "\n",
    "    \n",
    "    # Schedule\n",
    "    for step in range(steps - 1):\n",
    "        # update the gains\n",
    "        gains = schedule(initial_gains, step, steps, target_stem=target_stem, schedule_type=schedule_type)\n",
    "        #print(\"Gains: \", gains)\n",
    "\n",
    "        # apply the gains to the separated sources\n",
    "        for i, stem_name in enumerate(model.sources):\n",
    "            separated_sources[:, i] *= gains[stem_name]\n",
    "        \n",
    "        # create the new mixture\n",
    "        new_mix = torch.zeros_like(mix)\n",
    "        for i, stem_name in enumerate(model.sources):\n",
    "            new_mix += separated_sources[:, i]\n",
    "\n",
    "        # separate the new mixture\n",
    "        separated_sources = separate_sources(model, new_mix, sample_rate=sample_rate, overlap=overlap, device=device, normalize=normalize)\n",
    "\n",
    "        if(checkSDREachStep or step == steps - 2):\n",
    "\n",
    "            # print(\"Control: \", checkSDREachStep or step == steps - 1)\n",
    "            # evaluate SDR for each stem\n",
    "            for i, stem_name in enumerate(model.sources):\n",
    "                original_stem = reference_stem.to(device)\n",
    "                predicted_stem = separated_sources[0, i].to(device)\n",
    "\n",
    "                # Calculate SDR\n",
    "                sdr_value = evaluate_sdr(original_stem, predicted_stem, device=device)\n",
    "\n",
    "                # save the SDR value in a dictionary\n",
    "                sdr_results[stem_name].append(sdr_value)\n",
    "                \n",
    "\n",
    "    return separated_sources, sdr_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressive_inference_across_dataset(\n",
    "    dataset_dict,\n",
    "    model,\n",
    "    sample_rate,\n",
    "    segment_length,\n",
    "    device,\n",
    "    normalize,\n",
    "    target_stem=\"vocals\",\n",
    "    steps=10,\n",
    "    schedule_type=\"linear\",\n",
    "    overlap=0.0,\n",
    "    initial_gains=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform progressive inference across the dataset.\n",
    "    Args:\n",
    "        dataset_dict (dict): Dictionary containing the dataset.\n",
    "        model: The separation model.\n",
    "        sample_rate: Sample rate of the audio.\n",
    "        segment_length: Length of each segment in seconds.\n",
    "        device: Device to run the model on (CPU or GPU).\n",
    "        normalize: Whether to normalize the input mixture.\n",
    "        steps: Number of steps for progressive inference.\n",
    "        schedule_type: Type of schedule ('linear', 'exponential', or 'constant').\n",
    "        overlap: Overlap between segments in seconds.\n",
    "        initial_gains: Initial gains for each stem.\n",
    "    Returns:\n",
    "        average_sdr (dict): Dictionary containing the average SDR for each stem.\n",
    "    \"\"\"\n",
    "    if initial_gains is None:\n",
    "        initial_gains = {stem: 0.25 for stem in [\"bass\", \"drums\", \"vocals\", \"other\"]}\n",
    "\n",
    "    #sdr_results = {stem: [] for stem in [\"bass\", \"drums\", \"vocals\", \"other\"]} # dictionary to store SDR results\n",
    "\n",
    "    sdr_collection_dict = [] # tensor to store SDR results for each track\n",
    "\n",
    "    for track_name, stems_dict in tqdm.tqdm(dataset_dict.items()):\n",
    "\n",
    "        # Ensure the mixture exists in the stems\n",
    "        if \"new_mixture\" not in stems_dict:\n",
    "            print(f\"Skipping track {track_name} as it does not contain a new mixture.\")\n",
    "            continue\n",
    "\n",
    "        # Load the mixture and move it to the correct device\n",
    "        mixture = stems_dict[\"new_mixture\"].to(device).unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        # Perform progressive inference\n",
    "        separated_sources, sdr_results_single_track = progressive_inference(\n",
    "            model,\n",
    "            mixture[:, :, :segment_length * sample_rate],\n",
    "            target_stem=target_stem,\n",
    "            reference_stem=stems_dict[target_stem].to(device),\n",
    "            initial_gains=initial_gains,\n",
    "            sample_rate=sample_rate,\n",
    "            overlap=overlap,\n",
    "            device=device,\n",
    "            normalize=normalize,\n",
    "            steps=steps,\n",
    "            schedule_type=schedule_type,\n",
    "            checkSDREachStep=True,\n",
    "        )\n",
    "        # Convert sdr_results_single_track to a tensor\n",
    "        sdr_tensor = torch.tensor([sdr_results_single_track[stem] for stem in [\"bass\", \"drums\", \"vocals\", \"other\"]])\n",
    "        # Append the SDR tensor to the collection\n",
    "        sdr_collection_dict.append(sdr_tensor)\n",
    "        sdr_collection = torch.stack(sdr_collection_dict)\n",
    "        #print(sdr_collection.shape)\n",
    "         \n",
    "    \n",
    "    # Evaluate the mean SDR for each stem\n",
    "    sdr_collection_mean = torch.mean(sdr_collection, dim=0)\n",
    "\n",
    "    sdr_collection_mean = torch.flip(sdr_collection_mean, dims=[1])\n",
    "    print(sdr_collection_mean.shape)\n",
    "    \n",
    "    return sdr_collection_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce to 10 tracks the dataset_dict\n",
    "dataset_dict_reduced = {k: dataset_dict[k] for k in list(dataset_dict)[:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separated sources volume: tensor(0.5159, device='mps:0')\n",
      "Separated sources volume: tensor(0.2166, device='mps:0')\n",
      "Separated sources volume: tensor(0.4392, device='mps:0')\n",
      "Separated sources volume: tensor(0.5407, device='mps:0')\n",
      "Initial SDR:  {'bass': [-39.529178619384766], 'drums': [-35.527137756347656], 'vocals': [11.059057235717773], 'other': [-25.207073211669922]}\n",
      "Separated source:  0\n",
      "Separated source:  1\n",
      "Separated source:  2\n",
      "Separated source:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# use the function to evaluate SDR across all the dataset using progressive inference\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m average_sdr = \u001b[43mprogressive_inference_across_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_dict_reduced\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mSEGMENT_LENGTH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_stem\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvocals\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlinear\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverlap\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mprogressive_inference_across_dataset\u001b[39m\u001b[34m(dataset_dict, model, sample_rate, segment_length, device, normalize, target_stem, steps, schedule_type, overlap, initial_gains)\u001b[39m\n\u001b[32m     48\u001b[39m separated_sources, sdr_results_single_track = progressive_inference(\n\u001b[32m     49\u001b[39m     model,\n\u001b[32m     50\u001b[39m     mixture[:, :, :segment_length * sample_rate],\n\u001b[32m   (...)\u001b[39m\u001b[32m     60\u001b[39m     checkSDREachStep=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     61\u001b[39m )\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Convert sdr_results_single_track to a tensor\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m sdr_tensor = torch.tensor([\u001b[43msdr_results_single_track\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m stem \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mbass\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdrums\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvocals\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mother\u001b[39m\u001b[33m\"\u001b[39m]])\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Append the SDR tensor to the collection\u001b[39;00m\n\u001b[32m     65\u001b[39m sdr_collection_dict.append(sdr_tensor)\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# use the function to evaluate SDR across all the dataset using progressive inference\n",
    "average_sdr = progressive_inference_across_dataset(\n",
    "    dataset_dict_reduced,\n",
    "    model,\n",
    "    sample_rate,\n",
    "    SEGMENT_LENGTH,\n",
    "    device,\n",
    "    target_stem=\"vocals\",\n",
    "    normalize=True,\n",
    "    steps=10,\n",
    "    schedule_type=\"linear\",\n",
    "    overlap=0.0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SDR results per stem: tensor([[-36.3256, -42.2025, -41.4395, -42.5473, -43.6873, -43.0958, -42.6080,\n",
      "         -42.1912, -41.8378, -41.5382],\n",
      "        [-45.3296, -44.2355, -41.4980, -40.2239, -39.3498, -38.5064, -37.6704,\n",
      "         -37.0464, -36.6580, -36.5059],\n",
      "        [  8.8973,   8.9699,   9.0566,   9.1801,   9.3389,   9.5220,   9.7004,\n",
      "           9.8550,   9.9822,  10.0908],\n",
      "        [-32.2011, -33.1726, -34.1649, -30.7485, -28.5430, -26.7495, -25.3243,\n",
      "         -24.3176, -23.7288, -23.5888]])\n"
     ]
    }
   ],
   "source": [
    "# plot average SDR results\n",
    "print(\"Average SDR results per stem:\", average_sdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert average_sdr tensor to a dictionary with numpy values\n",
    "average_sdr_dict = {\n",
    "    \"bass\": average_sdr[0].cpu().numpy(),\n",
    "    \"drums\": average_sdr[1].cpu().numpy(),\n",
    "    \"vocals\": average_sdr[2].cpu().numpy(),\n",
    "    \"other\": average_sdr[3].cpu().numpy()\n",
    "}\n",
    "\n",
    "# Plot the SDR results with x-axis the SDR values and y-axis the steps using average_sdr_dict. \n",
    "def plot_sdr_results(average_sdr_dict):\n",
    "    \"\"\"\n",
    "    Plot the SDR results for each stem.\n",
    "\n",
    "    Args:\n",
    "        average_sdr_dict (dict): Dictionary containing the average SDR for each stem.\n",
    "    \"\"\"\n",
    "    steps = np.arange(1, len(average_sdr_dict[\"bass\"]) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(steps, average_sdr_dict[\"bass\"], label=\"Bass\", color='blue')\n",
    "    plt.plot(steps, average_sdr_dict[\"drums\"], label=\"Drums\", color='orange')\n",
    "    plt.plot(steps, average_sdr_dict[\"vocals\"], label=\"Vocals\", color='green')\n",
    "    plt.plot(steps, average_sdr_dict[\"other\"], label=\"Other\", color='red')\n",
    "\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Average SDR (dB)')\n",
    "    plt.title('Average SDR for Each Stem Over Steps')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "plot_sdr_results(average_sdr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sdr_with_dynamic_gains(\n",
    "    dataset_dict, initial_gains, model, device,\n",
    "    sample_rate, segment_length=30, steps=10, target_stem=\"vocals\"):\n",
    "    \"\"\"\n",
    "    Evaluate SDR with dynamic gain modification for a specific target stem and save the SDR for each stem at each iteration.\n",
    "\n",
    "    Parameters:\n",
    "        dataset_dict (dict): Dataset containing tracks and stems.\n",
    "        initial_gains (torch.Tensor): Initial gains for the stems (e.g., [0.25, 0.25, 0.25, 0.25]).\n",
    "        model (torch.nn.Module): Separation model.\n",
    "        device (str or torch.device): Device to run the evaluation on.\n",
    "        sample_rate (int): Sample rate of the audio.\n",
    "        segment_length (int): Length of the audio segments in seconds.\n",
    "        steps (int): Number of steps to modify the gains.\n",
    "        target_stem (str): The name of the stem to apply the target gain (e.g., \"vocals\").\n",
    "\n",
    "    Returns:\n",
    "        dict: SDR results structured as:\n",
    "              { track_name: [ { 'step': step, 'gains': gains_list, 'sdrs': {stem: sdr_value, ...} }, ... ] }\n",
    "    \"\"\"\n",
    "    # Map stem names to indices\n",
    "    stem_indices = {\"drums\": 0, \"bass\": 1, \"vocals\": 2, \"other\": 3}\n",
    "\n",
    "    if target_stem not in stem_indices:\n",
    "        raise ValueError(f\"Invalid target stem '{target_stem}'. Must be one of {list(stem_indices.keys())}.\")\n",
    "    target_stem_idx = stem_indices[target_stem]\n",
    "\n",
    "    sdr_results = {}\n",
    "\n",
    "    for track in tqdm.tqdm(dataset_dict, desc=f\"Evaluating SDR with Dynamic Gains for '{target_stem}'\"):\n",
    "        # Retrieve the original stems and move them to the device\n",
    "        stems = dataset_dict[track]\n",
    "        for stem_name in stems:\n",
    "            stems[stem_name] = stems[stem_name].to(device)\n",
    "        \n",
    "        # Skip the track if any main stem is missing\n",
    "        if any(stem not in stems for stem in [\"drums\", \"bass\", \"vocals\", \"other\"]):\n",
    "            print(f\"Track '{track}' is missing some stems. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        #print(f\"\\nEvaluating SDR for track '{track}' with dynamic gains for '{target_stem}'...\")\n",
    "        track_results = []  # List to store results for each step\n",
    "\n",
    "        for step in range(steps + 1):\n",
    "            # Update gains: increase the target stem's gain gradually\n",
    "            target_gain = initial_gains[target_stem_idx] + (step * 0.05)  # Increment target stem gain\n",
    "            \n",
    "            # normalize the target gain array\n",
    "            other_gains = [gain / max(other_gains) for gain in other_gains]\n",
    "\n",
    "            # 1.00 1.00 1.00 1.00 -> 1.00 1.00 1.00 1.05 -> 0.95 0.95 0.95 1.00\n",
    "            # 1.00 1.00 1.00 1.00 -> 1.00 1.00 1.00 1.05 -> 0.247 0.247 0.247 0.259 -> 0.95 0.95 0.95 1.00\n",
    "\n",
    "            modified_gains = torch.tensor(other_gains, device=device)\n",
    "\n",
    "            # Create a new mixture with modified gains\n",
    "            new_mix = (\n",
    "                modified_gains[0] * stems[\"drums\"] +\n",
    "                modified_gains[1] * stems[\"bass\"] +\n",
    "                modified_gains[2] * stems[\"vocals\"] +\n",
    "                modified_gains[3] * stems[\"other\"]\n",
    "            )\n",
    "            new_mix = new_mix.to(torch.float32).to(device)\n",
    "\n",
    "            # Ensure model parameters are on the correct device and type\n",
    "            for param in model.parameters():\n",
    "                param.data = param.data.to(torch.float32).to(device)\n",
    "\n",
    "            # Perform source separation with a batch dimension added\n",
    "            try:\n",
    "                sources_tensor = separate_sources(\n",
    "                    model,\n",
    "                    new_mix[None],  # Add batch dimension\n",
    "                    segment=segment_length,\n",
    "                    overlap=0.0,\n",
    "                    device=device\n",
    "                )[0]  # Remove batch dimension\n",
    "            except Exception as e:\n",
    "                print(f\"Error during separation for track '{track}' at step {step}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Map predicted sources to their names\n",
    "            predicted_stems = dict(zip(model.sources, list(sources_tensor)))\n",
    "\n",
    "            # For each stem, calculate SDR if available\n",
    "            iteration_sdr = {}\n",
    "            for stem in model.sources:\n",
    "                if stem in stems:\n",
    "                    ref_stem = stems[stem].to(device)\n",
    "                    pred_stem = predicted_stems[stem]\n",
    "                    try:\n",
    "                        sdr = evaluate_sdr(ref_stem, pred_stem, device=device)\n",
    "                        iteration_sdr[stem] = sdr\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error computing SDR for track '{track}', stem '{stem}', step {step}: {e}\")\n",
    "                        iteration_sdr[stem] = None\n",
    "                else:\n",
    "                    iteration_sdr[stem] = None\n",
    "\n",
    "            # Save iteration results\n",
    "            track_results.append({\n",
    "                'step': step,\n",
    "                'gains': modified_gains.tolist(),\n",
    "                'sdrs': iteration_sdr\n",
    "            })\n",
    "            #print(f\"Step {step}/{steps}, Gains: {modified_gains.tolist()}, SDRs: {iteration_sdr}\")\n",
    "\n",
    "        sdr_results[track] = track_results\n",
    "\n",
    "    return sdr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_gains = torch.tensor([0.25, 0.25, 0.25, 0.25], device=device)\n",
    "# track_names = list(dataset_dict.keys())\n",
    "# track_chosen = track_names[30]\n",
    "# stems = dataset_dict[track_chosen]\n",
    "\n",
    "# sdr_results = evaluate_sdr_with_dynamic_gains(\n",
    "#     dataset_dict=dataset_dict,\n",
    "#     initial_gains=initial_gains,\n",
    "#     model=model.to(device),\n",
    "#     device=device, \n",
    "#     sample_rate=sample_rate,\n",
    "#     segment_length=30,\n",
    "#     steps=10,\n",
    "#     target_stem=\"vocals\"  # Specify the target stem to evaluate\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume sdr_results is a dict structured as:\n",
    "# {track_name: [ { 'step': step, 'gains': [...], 'sdrs': {stem: sdr_value, ...} }, ... ] }\n",
    "\n",
    "# Determine the number of steps from one example. (10 steps)\n",
    "# example_track = next(iter(sdr_results.values()))\n",
    "# n_steps = len(example_track)\n",
    "\n",
    "# # Collect all stem names present in the results.\n",
    "# stem_set = set()\n",
    "# for track_results in sdr_results.values():\n",
    "#     for entry in track_results:\n",
    "#         stem_set.update(entry['sdrs'].keys())\n",
    "# stem_names = sorted(list(stem_set))\n",
    "\n",
    "# # Create a dictionary to hold mean SDR per stem for each step.\n",
    "# mean_sdr = {stem: [] for stem in stem_names}\n",
    "\n",
    "# # Loop over steps and aggregate SDR over all tracks per stem.\n",
    "# for step in range(n_steps):\n",
    "#     # For each stem, gather values across tracks.\n",
    "#     step_values = {stem: [] for stem in stem_names}\n",
    "#     for track_results in sdr_results.values():\n",
    "#         # safeguard if a track doesn't have all steps\n",
    "#         if step < len(track_results):\n",
    "#             entry = track_results[step]\n",
    "#             for stem in stem_names:\n",
    "#                 sdr_val = entry['sdrs'].get(stem)\n",
    "#                 if sdr_val is not None:\n",
    "#                     step_values[stem].append(sdr_val)\n",
    "#     # Compute the mean for each stem at this step.\n",
    "#     for stem in stem_names:\n",
    "#         if step_values[stem]:\n",
    "#             mean_sdr[stem].append(np.mean(step_values[stem]))\n",
    "#         else:\n",
    "#             mean_sdr[stem].append(np.nan)\n",
    "\n",
    "# # Plot mean SDR vs. step for each stem.\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for stem in stem_names:\n",
    "#     plt.plot(range(n_steps), mean_sdr[stem], label=stem)\n",
    "\n",
    "# plt.xlabel(\"Step\")\n",
    "# plt.ylabel(\"Mean SDR (dB)\")\n",
    "# plt.title(\"Mean SDR across tracks for each step and stem\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sdr_results\n",
    "# def plot_sdr_results(sdr_results, track_name, steps):\n",
    "#     \"\"\"\n",
    "#     Plot SDR results for a specific track.\n",
    "\n",
    "#     Args:\n",
    "#         sdr_results (dict): Dictionary containing SDR results.\n",
    "#         track_name (str): Name of the track to plot.\n",
    "#         steps (int): Number of steps in the schedule.\n",
    "#     \"\"\"\n",
    "#     if track_name not in sdr_results:\n",
    "#         print(f\"Track '{track_name}' not found in SDR results.\")\n",
    "#         return\n",
    "\n",
    "#     track_data = sdr_results[track_name]\n",
    "\n",
    "#     # Prepare data for plotting\n",
    "#     steps_list = [entry['step'] for entry in track_data]\n",
    "#     gains_list = [entry['gains'] for entry in track_data]\n",
    "#     sdrs_list = [entry['sdrs'] for entry in track_data]\n",
    "\n",
    "#     # Create subplots\n",
    "#     fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "#     # Plot gains\n",
    "#     for i, gain in enumerate(zip(*gains_list)):\n",
    "#         ax1.plot(steps_list, gain, label=f\"Gain {i + 1}\", linestyle='--')\n",
    "\n",
    "#     ax1.set_xlabel(\"Step\")\n",
    "#     ax1.set_ylabel(\"Gains\")\n",
    "#     ax1.set_title(f\"Gains and SDR for Track: {track_name}\")\n",
    "#     ax1.legend(loc='upper left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
