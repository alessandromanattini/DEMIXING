{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progressive Inference for Music Demixing ID: L12\n",
    "Description: Using denoising diffusion approaches to train music demixing (MDX) models is\n",
    "promising but requires retraining large and carefully tuned neural networks (Plaja-Roglans,\n",
    "2022). Instead, we will explore a related yet different approach: can we improve separation\n",
    "quality solely by scheduling the inference process using a diffusion-inspired strategy even\n",
    "without retraining? By experimenting with existing MDX models (Spleeter by Deezer,Meta’s Demucs, ByteDance’s BS-Roformer, etc.), this project offers an exciting opportunity\n",
    "to explore and possibly enhance the performance of state-of-the-art AI techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "\n",
    "\n",
    "(Plaja-Roglans, 2022) https://ismir2022program.ismir.net/poster_262.html\n",
    "Denoising Diffusion Probabilistic Models: https://arxiv.org/abs/2006.11239\n",
    "MDX Challenge 2021: https://arxiv.org/abs/2108.13559\n",
    "MDX Challenge 2023: https://arxiv.org/abs/2308.06979\n",
    "Overview of state-of-the-art MDX models:\n",
    "https://paperswithcode.com/sota/music-source-separation-on-musdb18-hq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary step: Install and Import Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: IPython in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (9.0.2)\n",
      "Requirement already satisfied: torch in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.6.0)\n",
      "Requirement already satisfied: torchaudio in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.6.0)\n",
      "Requirement already satisfied: tqdm in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: numpy in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (2.2.4)\n",
      "Requirement already satisfied: matplotlib in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (3.10.1)\n",
      "Collecting librosa (from -r requirements.txt (line 7))\n",
      "  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: decorator in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from IPython->-r requirements.txt (line 1)) (4.13.0)\n",
      "Requirement already satisfied: filelock in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (3.18.0)\n",
      "Requirement already satisfied: networkx in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from torch->-r requirements.txt (line 2)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Collecting audioread>=2.1.9 (from librosa->-r requirements.txt (line 7))\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numba>=0.51.0 (from librosa->-r requirements.txt (line 7))\n",
      "  Downloading numba-0.61.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from librosa->-r requirements.txt (line 7)) (1.15.2)\n",
      "Collecting scikit-learn>=1.1.0 (from librosa->-r requirements.txt (line 7))\n",
      "  Using cached scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting joblib>=1.0 (from librosa->-r requirements.txt (line 7))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from librosa->-r requirements.txt (line 7)) (0.13.1)\n",
      "Collecting pooch>=1.1 (from librosa->-r requirements.txt (line 7))\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa->-r requirements.txt (line 7))\n",
      "  Downloading soxr-0.5.0.post1-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Collecting lazy_loader>=0.1 (from librosa->-r requirements.txt (line 7))\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa->-r requirements.txt (line 7))\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from jedi>=0.16->IPython->-r requirements.txt (line 1)) (0.8.4)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa->-r requirements.txt (line 7))\n",
      "  Downloading llvmlite-0.44.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from pexpect>4.3->IPython->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 7)) (4.3.7)\n",
      "Collecting requests>=2.19.0 (from pooch>=1.1->librosa->-r requirements.txt (line 7))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: wcwidth in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->-r requirements.txt (line 1)) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 6)) (1.17.0)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.1.0->librosa->-r requirements.txt (line 7))\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 7)) (1.17.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from stack_data->IPython->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from stack_data->IPython->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from stack_data->IPython->-r requirements.txt (line 1)) (0.2.3)\n",
      "Requirement already satisfied: pycparser in /Users/filippo/miniconda3/envs/MAECap/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 7)) (2.22)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7))\n",
      "  Using cached charset_normalizer-3.4.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7))\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7))\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7))\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.0-cp311-cp311-macosx_11_0_arm64.whl (81 kB)\n",
      "Downloading numba-0.61.2-cp311-cp311-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl (11.1 MB)\n",
      "Downloading soxr-0.5.0.post1-cp311-cp311-macosx_11_0_arm64.whl (159 kB)\n",
      "Downloading llvmlite-0.44.0-cp311-cp311-macosx_11_0_arm64.whl (26.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.2/26.2 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp311-cp311-macosx_10_9_universal2.whl (194 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, threadpoolctl, soxr, msgpack, llvmlite, lazy_loader, joblib, idna, charset-normalizer, certifi, audioread, scikit-learn, requests, numba, pooch, librosa\n",
      "Successfully installed audioread-3.0.1 certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 joblib-1.4.2 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.44.0 msgpack-1.1.0 numba-0.61.2 pooch-1.8.2 requests-2.32.3 scikit-learn-1.6.1 soxr-0.5.0.post1 threadpoolctl-3.6.0 urllib3-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the Model and Device Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HDemucs(\n",
       "  (freq_encoder): ModuleList(\n",
       "    (0): _HEncLayer(\n",
       "      (conv): Conv2d(4, 48, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): _HEncLayer(\n",
       "      (conv): Conv2d(48, 96, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): _HEncLayer(\n",
       "      (conv): Conv2d(96, 192, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): _HEncLayer(\n",
       "      (conv): Conv2d(192, 384, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): _HEncLayer(\n",
       "      (conv): Conv2d(384, 768, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): _HEncLayer(\n",
       "      (conv): Conv1d(768, 1536, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv1d(1536, 3072, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (freq_decoder): ModuleList(\n",
       "    (0): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(1536, 768, kernel_size=(4,), stride=(2,))\n",
       "      (norm2): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv1d(1536, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (1): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(768, 384, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv2d(768, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (2): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(384, 192, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (3): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(192, 96, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (4): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(96, 48, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (5): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(48, 16, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "  )\n",
       "  (time_encoder): ModuleList(\n",
       "    (0): _HEncLayer(\n",
       "      (conv): Conv1d(2, 48, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(48, 96, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): _HEncLayer(\n",
       "      (conv): Conv1d(48, 96, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): _HEncLayer(\n",
       "      (conv): Conv1d(96, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): _HEncLayer(\n",
       "      (conv): Conv1d(192, 384, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): _HEncLayer(\n",
       "      (conv): Conv1d(384, 768, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Identity()\n",
       "      (norm2): Identity()\n",
       "      (dconv): Identity()\n",
       "    )\n",
       "  )\n",
       "  (time_decoder): ModuleList(\n",
       "    (0): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(768, 384, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
       "      (rewrite): Identity()\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (1): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(384, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (2): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(192, 96, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(192, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (3): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(96, 48, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(96, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (4): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(48, 8, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(48, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "  )\n",
       "  (freq_emb): _ScaledEmbedding(\n",
       "    (embedding): Embedding(512, 48)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundle = torchaudio.pipelines.HDEMUCS_HIGH_MUSDB_PLUS\n",
    "model = bundle.get_model()\n",
    "sample_rate = bundle.sample_rate\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # windows\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\") # macOS\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the Dataset and Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset at: https://zenodo.org/records/3338373"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_LENGTH = 30  # 30 seconds of audio from each song\n",
    "DATASET_FOLDER =  \"./musdb18hq/test\" # dataset should be inside the prject folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary creation\n",
    "\n",
    "(Dataset Structure: `{track_folder -> {stem_name -> waveform}`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_non_silence_start(song):\n",
    "    \"\"\"\n",
    "    Given a song (dictionary of stem names -> waveform),\n",
    "    use librosa.effects.trim to find the starting index of non-silent \n",
    "    segments for each stem and return the highest start index.\n",
    "    \"\"\"\n",
    "    max_start = 0\n",
    "    for stem, waveform in song.items():\n",
    "        # Convert tensor waveform to numpy if necessary\n",
    "        if hasattr(waveform, \"detach\"):\n",
    "            waveform_np = waveform.detach().cpu().numpy()\n",
    "        else:\n",
    "            waveform_np = waveform\n",
    "        \n",
    "        # If waveform is multi-channel (shape: channels x samples)\n",
    "        if waveform_np.ndim > 1:\n",
    "            # Convert to mono using librosa.to_mono\n",
    "            waveform_np = librosa.to_mono(waveform_np)\n",
    "        else:\n",
    "            waveform_np = waveform_np.squeeze()\n",
    "\n",
    "        # Trim leading and trailing silence\n",
    "        # trim returns a tuple (trimmed_audio, (start, end))\n",
    "        trimmed, indices = librosa.effects.trim(waveform_np)\n",
    "        if indices.size and indices[0] > max_start:\n",
    "            max_start = indices[0]\n",
    "            \n",
    "    return max_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stem_silent(waveform, threshold=1e-4):\n",
    "    \"\"\"\n",
    "    Determines if a given song stem is not silent.\n",
    "    \n",
    "    Args:\n",
    "        waveform (torch.Tensor or np.ndarray): The audio waveform of the stem.\n",
    "        threshold (float): The amplitude threshold below which the stem is considered silent.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the stem is not silent, False otherwise.\n",
    "    \"\"\"\n",
    "    # Convert tensor waveform to numpy if necessary\n",
    "    if hasattr(waveform, \"detach\"):\n",
    "        waveform = waveform.detach().cpu().numpy()\n",
    "    \n",
    "    # If waveform is multi-channel (shape: channels x samples), convert to mono\n",
    "    if waveform.ndim > 1:\n",
    "        waveform = librosa.to_mono(waveform)\n",
    "    \n",
    "    # Check if the maximum absolute amplitude exceeds the threshold\n",
    "    return np.max(np.abs(waveform)) < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_dataset():\n",
    "    \"\"\"\n",
    "    Load the dataset from the specified folder.\n",
    "    Each subfolder in the dataset corresponds to a song.\n",
    "    Each song contains multiple stems (e.g., mixture, drums, bass, etc.).\n",
    "    Returns:\n",
    "        dataset_dict (dict): A dictionary where keys are track folders and values are dictionaries of stems.\n",
    "    \"\"\"\n",
    "\n",
    "    # sorted list of folders in the dataset\n",
    "    track_folders = sorted(\n",
    "        folder for folder in os.listdir(DATASET_FOLDER)\n",
    "        if os.path.isdir(os.path.join(DATASET_FOLDER, folder))\n",
    "    )\n",
    "\n",
    "    # Dictionary to store {track_folder -> {stem_name -> waveform}}\n",
    "    dataset_dict = {}\n",
    "\n",
    "    # Each subfolder in musdb18hq/test corresponds to a song\n",
    "    for track_folder in track_folders:\n",
    "        track_path = os.path.join(DATASET_FOLDER, track_folder)\n",
    "        if not os.path.isdir(track_path):\n",
    "            continue\n",
    "\n",
    "        # Prepare a sub-dictionary for this song\n",
    "        stems_dict = {}\n",
    "        stem_names = [\"mixture\", \"drums\", \"bass\", \"vocals\", \"other\"]\n",
    "        \n",
    "        for stem_name in stem_names:\n",
    "            file_path = os.path.abspath(os.path.join(track_path, f\"{stem_name}.wav\"))\n",
    "            \n",
    "            if not os.path.isfile(file_path):\n",
    "                print(f\"Warning: file not found {file_path}\")\n",
    "                continue\n",
    "\n",
    "            # Load full audio\n",
    "            print(f\"Loading {file_path}...\")\n",
    "            waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "            stems_dict[stem_name] = waveform\n",
    "        \n",
    "        max_start = get_max_non_silence_start(stems_dict)\n",
    "\n",
    "        # If the stem is silent, remove it from the dictionary else trim it\n",
    "        for stem_name, waveform in stems_dict.items():\n",
    "            if is_stem_silent(waveform) or waveform.shape[1] < SEGMENT_LENGTH * sample_rate + max_start:\n",
    "                print(f\"Removing silent stem: {stem_name}\")\n",
    "                del stems_dict[stem_name]\n",
    "            else:\n",
    "                # Trim the waveform to the max_start to segment samples\n",
    "                duration = SEGMENT_LENGTH * sample_rate + max_start\n",
    "                stems_dict[stem_name] = waveform[:, max_start:duration]\n",
    "\n",
    "        dataset_dict[track_folder] = stems_dict\n",
    "\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Load the dataset from the musdb18hq_trimmed folder.\n",
    "    Each subfolder in the dataset corresponds to a song.\n",
    "    Each song contains multiple stems (e.g., mixture, drums, bass, etc.).\n",
    "    Returns:\n",
    "        dataset_dict (dict): A dictionary where keys are track folders and values are dictionaries of stems.\n",
    "    \"\"\"\n",
    "    dataset_dict = {}\n",
    "\n",
    "    for track_folder in os.listdir(\"musdb18hq_trimmed\"):\n",
    "        track_path = os.path.join(\"musdb18hq_trimmed\", track_folder)\n",
    "        if not os.path.isdir(track_path):\n",
    "            continue\n",
    "\n",
    "        # Prepare a sub-dictionary for this song\n",
    "        stems_dict = {}\n",
    "        \n",
    "        for stem_name in [\"mixture\", \"drums\", \"bass\", \"vocals\", \"other\"]:\n",
    "            file_path = os.path.abspath(os.path.join(track_path, f\"{stem_name}.wav\"))\n",
    "            \n",
    "            if not os.path.isfile(file_path):\n",
    "                print(f\"Warning: file not found {file_path}\")\n",
    "                continue\n",
    "\n",
    "            # Load full audio\n",
    "            waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "            stems_dict[stem_name] = waveform\n",
    "            \n",
    "        dataset_dict[track_folder] = stems_dict\n",
    "        \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists.\n",
      "Dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(\"musdb18hq_trimmed\"):\n",
    "    print(\"Dataset already exists.\")\n",
    "    # Load the trimmed dataset\n",
    "    dataset_dict = load_dataset()\n",
    "    print(\"Dataset loaded.\")\n",
    "else:\n",
    "    print(\"Loading dataset...\")\n",
    "    dataset_dict = load_and_process_dataset()\n",
    "    print(\"Dataset loaded.\")\n",
    "    \n",
    "    # Save the trimmed dataset\n",
    "    os.makedirs(\"musdb18hq_trimmed\", exist_ok=True)\n",
    "    for track_folder, stems_dict in dataset_dict.items():\n",
    "    \n",
    "        track_path = os.path.join(\"musdb18hq_trimmed\", track_folder)\n",
    "        os.makedirs(track_path, exist_ok=True)\n",
    "        \n",
    "        #Add new_mixture file to the track folder as the sum of the stems\n",
    "        new_mixture = torch.zeros((2, SEGMENT_LENGTH * sample_rate))\n",
    "        for stem_name, waveform in stems_dict.items():\n",
    "            \n",
    "            file_path = os.path.join(track_path, f\"{stem_name}.wav\")\n",
    "            torchaudio.save(file_path, waveform, sample_rate=sample_rate)\n",
    "\n",
    "            # Generation of the new_mixture file\n",
    "            if stem_name != \"mixture\":\n",
    "                new_mixture += waveform\n",
    "                \n",
    "            # Add the new_mixture to the track folder\n",
    "            new_mixture = new_mixture[:, :SEGMENT_LENGTH * sample_rate]\n",
    "            new_mixture_path = os.path.join(track_path, \"new_mixture.wav\")\n",
    "            torchaudio.save(new_mixture_path, new_mixture, sample_rate)\n",
    "            print(f\"Saved new mixture to {new_mixture_path}\")\n",
    "    print(\"Trimmed dataset saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimmed tracks check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys in dataset_dict: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of keys in dataset_dict:\", len(dataset_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAECap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
