{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progressive Inference for Music Demixing ID: L12\n",
    "Description: Using denoising diffusion approaches to train music demixing (MDX) models is\n",
    "promising but requires retraining large and carefully tuned neural networks (Plaja-Roglans,\n",
    "2022). Instead, we will explore a related yet different approach: can we improve separation\n",
    "quality solely by scheduling the inference process using a diffusion-inspired strategy even\n",
    "without retraining? By experimenting with existing MDX models (Spleeter by Deezer,Meta’s Demucs, ByteDance’s BS-Roformer, etc.), this project offers an exciting opportunity\n",
    "to explore and possibly enhance the performance of state-of-the-art AI techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "\n",
    "\n",
    "(Plaja-Roglans, 2022) https://ismir2022program.ismir.net/poster_262.html\n",
    "Denoising Diffusion Probabilistic Models: https://arxiv.org/abs/2006.11239\n",
    "MDX Challenge 2021: https://arxiv.org/abs/2108.13559\n",
    "MDX Challenge 2023: https://arxiv.org/abs/2308.06979\n",
    "Overview of state-of-the-art MDX models:\n",
    "https://paperswithcode.com/sota/music-source-separation-on-musdb18-hq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary step: Install and Import Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: IPython in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (9.1.0)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (2.6.0)\n",
      "Requirement already satisfied: torchaudio in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (2.6.0)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (2.2.4)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from -r requirements.txt (line 6)) (3.10.1)\n",
      "Requirement already satisfied: librosa in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from -r requirements.txt (line 7)) (0.11.0)\n",
      "Requirement already satisfied: decorator in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from IPython->-r requirements.txt (line 1)) (5.14.3)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (4.13.1)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from torch->-r requirements.txt (line 2)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (0.61.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (1.4.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: standard-aifc in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (3.13.0)\n",
      "Requirement already satisfied: standard-sunau in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from librosa->-r requirements.txt (line 7)) (3.13.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from jedi>=0.16->IPython->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 7)) (0.44.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from pexpect>4.3->IPython->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 7)) (4.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 7)) (2.32.3)\n",
      "Requirement already satisfied: wcwidth in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->-r requirements.txt (line 1)) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 6)) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from scikit-learn>=1.1.0->librosa->-r requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 7)) (1.17.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from stack_data->IPython->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from stack_data->IPython->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from stack_data->IPython->-r requirements.txt (line 1)) (0.2.3)\n",
      "Requirement already satisfied: standard-chunk in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from standard-aifc->librosa->-r requirements.txt (line 7)) (3.13.0)\n",
      "Requirement already satisfied: audioop-lts in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from standard-aifc->librosa->-r requirements.txt (line 7)) (0.2.1)\n",
      "Requirement already satisfied: pycparser in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 7)) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/maeCap/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the Model and Device Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HDemucs(\n",
       "  (freq_encoder): ModuleList(\n",
       "    (0): _HEncLayer(\n",
       "      (conv): Conv2d(4, 48, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): _HEncLayer(\n",
       "      (conv): Conv2d(48, 96, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): _HEncLayer(\n",
       "      (conv): Conv2d(96, 192, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): _HEncLayer(\n",
       "      (conv): Conv2d(192, 384, kernel_size=(8, 1), stride=(4, 1), padding=(2, 0))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): _HEncLayer(\n",
       "      (conv): Conv2d(384, 768, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv2d(768, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm2): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(768, 192, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(192, 192, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=384, out_features=192, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(192, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(192, 1536, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 1536, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): _HEncLayer(\n",
       "      (conv): Conv1d(768, 1536, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv1d(1536, 3072, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): _BLSTM(\n",
       "              (lstm): LSTM(384, 384, num_layers=2, bidirectional=True)\n",
       "              (linear): Linear(in_features=768, out_features=384, bias=True)\n",
       "            )\n",
       "            (4): _LocalState(\n",
       "              (content): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (key): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "              (query_decay): Conv1d(384, 16, kernel_size=(1,), stride=(1,))\n",
       "              (proj): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (5): Conv1d(384, 3072, kernel_size=(1,), stride=(1,))\n",
       "            (6): GroupNorm(1, 3072, eps=1e-05, affine=True)\n",
       "            (7): GLU(dim=1)\n",
       "            (8): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (freq_decoder): ModuleList(\n",
       "    (0): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(1536, 768, kernel_size=(4,), stride=(2,))\n",
       "      (norm2): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv1d(1536, 3072, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): GroupNorm(4, 3072, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (1): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(768, 384, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
       "      (rewrite): Conv2d(768, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): GroupNorm(4, 1536, eps=1e-05, affine=True)\n",
       "    )\n",
       "    (2): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(384, 192, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (3): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(192, 96, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (4): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(96, 48, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (5): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose2d(48, 16, kernel_size=(8, 1), stride=(4, 1))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "  )\n",
       "  (time_encoder): ModuleList(\n",
       "    (0): _HEncLayer(\n",
       "      (conv): Conv1d(2, 48, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(48, 96, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(48, 12, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 12, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(12, 96, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): _HEncLayer(\n",
       "      (conv): Conv1d(48, 96, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(96, 24, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 24, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(24, 192, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 192, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): _HEncLayer(\n",
       "      (conv): Conv1d(96, 192, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(192, 48, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 48, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(48, 384, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 384, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): _HEncLayer(\n",
       "      (conv): Conv1d(192, 384, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): Identity()\n",
       "      (rewrite): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "      (norm2): Identity()\n",
       "      (dconv): _DConv(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(384, 96, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): GroupNorm(1, 96, eps=1e-05, affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Conv1d(96, 768, kernel_size=(1,), stride=(1,))\n",
       "            (4): GroupNorm(1, 768, eps=1e-05, affine=True)\n",
       "            (5): GLU(dim=1)\n",
       "            (6): _LayerScale()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): _HEncLayer(\n",
       "      (conv): Conv1d(384, 768, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "      (norm1): GroupNorm(4, 768, eps=1e-05, affine=True)\n",
       "      (rewrite): Identity()\n",
       "      (norm2): Identity()\n",
       "      (dconv): Identity()\n",
       "    )\n",
       "  )\n",
       "  (time_decoder): ModuleList(\n",
       "    (0): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(768, 384, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): GroupNorm(4, 384, eps=1e-05, affine=True)\n",
       "      (rewrite): Identity()\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (1): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(384, 192, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(384, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (2): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(192, 96, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(192, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (3): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(96, 48, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(96, 192, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "    (4): _HDecLayer(\n",
       "      (conv_tr): ConvTranspose1d(48, 8, kernel_size=(8,), stride=(4,))\n",
       "      (norm2): Identity()\n",
       "      (rewrite): Conv1d(48, 96, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm1): Identity()\n",
       "    )\n",
       "  )\n",
       "  (freq_emb): _ScaledEmbedding(\n",
       "    (embedding): Embedding(512, 48)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundle = torchaudio.pipelines.HDEMUCS_HIGH_MUSDB_PLUS\n",
    "model = bundle.get_model()\n",
    "sample_rate = bundle.sample_rate\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # windows\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\") # macOS\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the Dataset and Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset at: https://zenodo.org/records/3338373"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLobal Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_LENGTH = 30  # 30 seconds of audio from each song\n",
    "DATASET_FOLDER =  \"./musdb18hq/test\" # dataset should be inside the prject folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary creation\n",
    "\n",
    "(Dataset Structure: `{track_folder -> {stem_name -> waveform}`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_non_silence_start(song):\n",
    "    \"\"\"\n",
    "    Given a song (dictionary of stem names -> waveform),\n",
    "    use librosa.effects.trim to find the starting index of non-silent \n",
    "    segments for each stem and return the highest start index.\n",
    "    \"\"\"\n",
    "    max_start = 0\n",
    "    for stem, waveform in song.items():\n",
    "        # Convert tensor waveform to numpy if necessary\n",
    "        if hasattr(waveform, \"detach\"):\n",
    "            waveform_np = waveform.detach().cpu().numpy()\n",
    "        else:\n",
    "            waveform_np = waveform\n",
    "        \n",
    "        # If waveform is multi-channel (shape: channels x samples)\n",
    "        if waveform_np.ndim > 1:\n",
    "            # Convert to mono using librosa.to_mono\n",
    "            waveform_np = librosa.to_mono(waveform_np)\n",
    "        else:\n",
    "            waveform_np = waveform_np.squeeze()\n",
    "\n",
    "        # Trim leading and trailing silence\n",
    "        # trim returns a tuple (trimmed_audio, (start, end))\n",
    "        trimmed, indices = librosa.effects.trim(waveform_np)\n",
    "        if indices.size and indices[0] > max_start:\n",
    "            max_start = indices[0]\n",
    "            \n",
    "    return max_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stem_silent(waveform, threshold=1e-4):\n",
    "    \"\"\"\n",
    "    Determines if a given song stem is not silent.\n",
    "    \n",
    "    Args:\n",
    "        waveform (torch.Tensor or np.ndarray): The audio waveform of the stem.\n",
    "        threshold (float): The amplitude threshold below which the stem is considered silent.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the stem is not silent, False otherwise.\n",
    "    \"\"\"\n",
    "    # Convert tensor waveform to numpy if necessary\n",
    "    if hasattr(waveform, \"detach\"):\n",
    "        waveform = waveform.detach().cpu().numpy()\n",
    "    \n",
    "    # If waveform is multi-channel (shape: channels x samples), convert to mono\n",
    "    if waveform.ndim > 1:\n",
    "        waveform = librosa.to_mono(waveform)\n",
    "    \n",
    "    # Check if the maximum absolute amplitude exceeds the threshold\n",
    "    return np.max(np.abs(waveform)) < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Users/giorgiomagalini/Documents/_DocumentiUtente/Uni/PoliMi/CAPSTONE/Code/DEMIXING/musdb18hq/test/AM Contra - Heart Peripheral/mixture.wav...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Couldn't find appropriate backend to handle uri /Users/giorgiomagalini/Documents/_DocumentiUtente/Uni/PoliMi/CAPSTONE/Code/DEMIXING/musdb18hq/test/AM Contra - Heart Peripheral/mixture.wav and format None.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# Load full audio\u001b[39;00m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     waveform, sr = \u001b[43mtorchaudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     stems_dict[stem_name] = waveform_segment\n\u001b[32m     33\u001b[39m max_start = get_max_non_silence_start(stems_dict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/maeCap/lib/python3.13/site-packages/torchaudio/_backend/utils.py:204\u001b[39m, in \u001b[36mget_load_func.<locals>.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m    119\u001b[39m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    120\u001b[39m     frame_offset: \u001b[38;5;28mint\u001b[39m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    126\u001b[39m     backend: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    127\u001b[39m ) -> Tuple[torch.Tensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m    128\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[32m    129\u001b[39m \n\u001b[32m    130\u001b[39m \u001b[33;03m    By default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m \u001b[33;03m            `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     backend = \u001b[43mdispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m backend.load(uri, frame_offset, num_frames, normalize, channels_first, \u001b[38;5;28mformat\u001b[39m, buffer_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/maeCap/lib/python3.13/site-packages/torchaudio/_backend/utils.py:116\u001b[39m, in \u001b[36mget_load_func.<locals>.dispatcher\u001b[39m\u001b[34m(uri, format, backend_name)\u001b[39m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m backend.can_decode(uri, \u001b[38;5;28mformat\u001b[39m):\n\u001b[32m    115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m backend\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find appropriate backend to handle uri \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and format \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mformat\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Couldn't find appropriate backend to handle uri /Users/giorgiomagalini/Documents/_DocumentiUtente/Uni/PoliMi/CAPSTONE/Code/DEMIXING/musdb18hq/test/AM Contra - Heart Peripheral/mixture.wav and format None."
     ]
    }
   ],
   "source": [
    "# sorted list of folders in the dataset\n",
    "track_folders = sorted(\n",
    "    folder for folder in os.listdir(DATASET_FOLDER)\n",
    "    if os.path.isdir(os.path.join(DATASET_FOLDER, folder))\n",
    ")\n",
    "\n",
    "# Dictionary to store {track_folder -> {stem_name -> waveform}}\n",
    "dataset_dict = {}\n",
    "\n",
    "# Each subfolder in musdb18hq/test corresponds to a song\n",
    "for track_folder in track_folders:\n",
    "    track_path = os.path.join(DATASET_FOLDER, track_folder)\n",
    "    if not os.path.isdir(track_path):\n",
    "        continue\n",
    "\n",
    "    # Prepare a sub-dictionary for this song\n",
    "    stems_dict = {}\n",
    "    stem_names = [\"mixture\", \"drums\", \"bass\", \"vocals\", \"other\"]\n",
    "    \n",
    "    for stem_name in stem_names:\n",
    "        file_path = os.path.abspath(os.path.join(track_path, f\"{stem_name}.wav\"))\n",
    "        \n",
    "        if not os.path.isfile(file_path):\n",
    "            print(f\"Warning: file not found {file_path}\")\n",
    "            continue\n",
    "\n",
    "        # Load full audio\n",
    "        print(f\"Loading {file_path}...\")\n",
    "        waveform, sr = torchaudio.load(file_path)\n",
    "\n",
    "        stems_dict[stem_name] = waveform_segment\n",
    "    \n",
    "    max_start = get_max_non_silence_start(stems_dict)\n",
    "\n",
    "    # If the stem is silent, remove it from the dictionary else trim it\n",
    "    for stem_name, waveform in stems_dict.items():\n",
    "        if is_stem_silent(waveform) or waveform.shape[1] < SEGMENT_LENGTH * sample_rate + max_start:\n",
    "            print(f\"Removing silent stem: {stem_name}\")\n",
    "            del stems_dict[stem_name]\n",
    "        else:\n",
    "            # Trim the waveform to the max_start\n",
    "            stems_dict[stem_name] = waveform[:, max_start:]\n",
    "\n",
    "    dataset_dict[track_folder] = stems_dict\n",
    "\n",
    "print(\"Loaded tracks:\", list(dataset_dict.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maeCap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
